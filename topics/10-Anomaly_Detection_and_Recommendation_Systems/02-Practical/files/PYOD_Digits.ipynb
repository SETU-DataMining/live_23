{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "9063b853",
      "metadata": {},
      "source": [
        "# Example using pyod"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e8c625a4",
      "metadata": {
        "lines_to_next_cell": 0
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3506761e",
      "metadata": {
        "tags": [
          "imports"
        ]
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import scipy.io\n",
        "import os.path as path\n",
        "from zipfile import ZipFile\n",
        "import urllib.request\n",
        "from scipy.io import loadmat"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5aa2e8b7",
      "metadata": {},
      "source": [
        "The dataset was sourced from ODDS and downloaded from [here](https://www.dropbox.com/s/n3wurjt8v9qi6nc/mnist.mat)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6a198d05",
      "metadata": {
        "lines_to_next_cell": 0
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "43539368",
      "metadata": {
        "tags": [
          "readData"
        ]
      },
      "outputs": [],
      "source": [
        "vNames = [\"v\"+str(i) for i in range(100)]\n",
        "zipDataFile = 'data/mnist.zip'\n",
        "matDataFile = 'data/mnist.mat'\n",
        "if path.exists(matDataFile):\n",
        "    print(\"Read {}\".format(matDataFile))\n",
        "    mnist = loadmat(matDataFile)\n",
        "    X = pd.DataFrame(data=mnist['X'], columns=vNames)\n",
        "    y = pd.DataFrame(data=mnist['y'], columns=['label'])\n",
        "elif path.exists(zipDataFile):\n",
        "    print(\"Read {}\".format(zipDataFile))\n",
        "    with ZipFile(zipDataFile, mode='r') as dataZip:\n",
        "        # Read the predictor (X) matrix based on the selected pixel columns\n",
        "        with dataZip.open('X.csv') as mnistX:\n",
        "            X = pd.DataFrame(data=pd.read_csv(mnistX,header=None), columns=vNames)\n",
        "        # Read the label (y) vector where\n",
        "        with dataZip.open('y.csv') as mnistY:\n",
        "            y = pd.DataFrame(data=pd.read_csv(mnistY,header=None), columns=['label'])\n",
        "else:\n",
        "    #with urllib.request.urlopen('https://www.dropbox.com/s/n3wurjt8v9qi6nc/mnist.mat') as response:\n",
        "    #    with open(\"mnist.mat\", \"wb\") as f:\n",
        "    #        f.write(response.read())\n",
        "    print('download the file using wget')\n",
        "X.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cf3c2b0e",
      "metadata": {},
      "source": [
        "Take a quick look at the data (note that its dimensions have already been reduced to 100)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8933a480",
      "metadata": {},
      "outputs": [],
      "source": [
        "X.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0e51c105",
      "metadata": {},
      "source": [
        "Now have a look at the labels, which are 0 (inlier) and 1 (outlier) - as decided by a human observer. This is taken as the ground truth."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c670b8aa",
      "metadata": {},
      "outputs": [],
      "source": [
        "y"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "942a721b",
      "metadata": {
        "lines_to_next_cell": 0
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "734dabd8",
      "metadata": {
        "tags": [
          "trainTestSplit"
        ]
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)\n",
        "n_test = len(y_test.index)\n",
        "n_all = len(y.index)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d7706e1c",
      "metadata": {},
      "source": [
        "Convert to simple numpy arrays for comparison"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "703d1721",
      "metadata": {},
      "outputs": [],
      "source": [
        "yTrain = y_train['label'].to_numpy()\n",
        "yTest = y_test['label'].to_numpy()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "52537f40",
      "metadata": {},
      "source": [
        "Assign the outlier_fraction. Note that we are \"cheating\" here, because the data is labeled and so we \"know\" the outliers. However, if the data was unlabeled we would need to estimate the outlier_fraction."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6b8db783",
      "metadata": {
        "lines_to_next_cell": 0
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e7f4973a",
      "metadata": {
        "tags": [
          "labOutliers"
        ]
      },
      "outputs": [],
      "source": [
        "n_outlier = len(y[(y['label']==1)])\n",
        "outlier_fraction = n_outlier / float(n_all)\n",
        "print('The entire set has {} rows with {} outliers so the outlier fraction is {}'.format(n_all,n_outlier,outlier_fraction))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "85033cfa",
      "metadata": {
        "lines_to_next_cell": 0
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e10b5d1a",
      "metadata": {
        "tags": [
          "useKnnClassifier"
        ]
      },
      "outputs": [],
      "source": [
        "from pyod.models.knn import KNN\n",
        "\n",
        "knn=KNN(contamination=outlier_fraction)\n",
        "knn.fit(X_train)\n",
        "\n",
        "# get the prediction labels of the training data\n",
        "y_train_pred = knn.labels_ \n",
        "y_train_pred"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1c1b4ff7",
      "metadata": {},
      "source": [
        "Get the outlier scores of the training data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "30b6a367",
      "metadata": {
        "lines_to_next_cell": 0
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "13a97ad0",
      "metadata": {
        "tags": [
          "getScores"
        ]
      },
      "outputs": [],
      "source": [
        "y_train_scores = knn.decision_scores_\n",
        "y_train_scores"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "760ae523",
      "metadata": {},
      "source": [
        "Get the outlier predictions on the test data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8df407ef",
      "metadata": {},
      "outputs": [],
      "source": [
        "y_test_pred = knn.predict(X_test)  \n",
        "y_test_pred"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7c755d2f",
      "metadata": {},
      "source": [
        "Get the outlier scores of the test data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3cb41d0e",
      "metadata": {},
      "outputs": [],
      "source": [
        "y_test_scores = knn.decision_function(X_test)\n",
        "y_test_scores"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7f9689d6",
      "metadata": {},
      "source": [
        "Find the number of 'misclassified' digits in the test set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e853fb93",
      "metadata": {
        "lines_to_next_cell": 0
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8706e3e2",
      "metadata": {
        "tags": [
          "countMisclassified"
        ]
      },
      "outputs": [],
      "source": [
        "n_errors = (y_test_pred != yTest).sum()\n",
        "print('No of Errors when applying knn to test set: {}'.format(n_errors))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3e29aece",
      "metadata": {},
      "source": [
        "Compute the accuracy of the outlier detection classifier on the test set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "49db9459",
      "metadata": {
        "lines_to_next_cell": 0
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "20160045",
      "metadata": {
        "tags": [
          "calcAccuracy"
        ]
      },
      "outputs": [],
      "source": [
        "accuracy = (n_test-n_errors)/float(n_test)\n",
        "print('Accuracy when applying knn to test set: {}'.format(accuracy))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3d1d327b",
      "metadata": {},
      "source": [
        "Derive the probabilities of class 0 (inlier) and class 1 (outlier) for each digit. Note that these probabilities sum to 1. The digit is an outlier if the latter (class=1) probability is greater than the former (class=0)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fb95ff48",
      "metadata": {},
      "outputs": [],
      "source": [
        "y_test_score_prob = knn.predict_proba(X_test, method='linear')\n",
        "y_test_score_prob"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "bd8d7e43",
      "metadata": {},
      "source": [
        "Outlier detection can be viewed as a classification so we can use the scikit-learn classification report to vierw how well the outlier classifier did."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "23dfe79a",
      "metadata": {
        "lines_to_next_cell": 0
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "70ed6cbc",
      "metadata": {
        "tags": [
          "getClassificationReport"
        ]
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import classification_report\n",
        "print(classification_report(y_test, y_test_pred))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e9b62994",
      "metadata": {
        "lines_to_next_cell": 0
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "673f6f31",
      "metadata": {
        "tags": [
          "getConfusionMatrix"
        ]
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "confusion_matrix(y_test, y_test_pred)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "753801c2",
      "metadata": {
        "lines_to_next_cell": 0
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "827c7106",
      "metadata": {
        "tags": [
          "presentConfusionMatrix"
        ]
      },
      "outputs": [],
      "source": [
        "trueInlier, falseOutlier, falseInlier, trueOutlier = confusion_matrix(y_test, y_test_pred).ravel()\n",
        "print(\"There were {} digits, of which\".format(n_test))\n",
        "print(\"{} inliers were classified correctly; {} outliers were classified correctly.\".format(trueInlier,trueOutlier))\n",
        "print(\"{} outliers were classified incorrectly; {} inliers were classified incorrectly.\".format(falseOutlier,falseInlier))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b63b0d57",
      "metadata": {},
      "source": [
        "Note that the false negative count is approximately the same as the false positive count, because the `outlier_fraction` is approximately correct, so the score threshold is approximately correct. However, more outliers were misclassified than were classified correctly. This is disappointing but is often found when the data is so unbalanced.\n",
        "\n",
        "_Exercise_\n",
        "\n",
        "1. We used the knn outlier detection algorithm and implictly used its default hyperparameter values: `n_neighbours` = 5, `method` = 'largest', `metric` = 'minkowski' and `p` = 2. Note that a Minkowski distance metric with p = 2 implies Euclidean distance. Try other hyperparameter value combinations, e.g. `k` = [3, 5, 7]; `method` = ['largest', 'mean', 'median']. Which combination gives the best performance?\n",
        "2. Try other outlier detection algorithms from pyod, such as those mentioned in class. Note that pyod offers many algorithms. Some example output from [pyod documentation](https://pyod.readthedocs.io/en/latest/) is shown below"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "367484ec",
      "metadata": {},
      "outputs": [],
      "source": [
        "from IPython.display import IFrame\n",
        "IFrame(\"../data/selected_pyod.pdf\", width=700, height=600)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
