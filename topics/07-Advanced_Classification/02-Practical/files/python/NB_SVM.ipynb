{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "98d47561",
      "metadata": {
        "tags": [
          "intro"
        ]
      },
      "source": [
        "# Using the Pima Indians Database to predict Diabetes Outcome\n",
        "\n",
        "The Pima are Native Americans based in Arizona. As a result of changes in diet and physical activity, they have developed a very high incidence of _Type 2 diabetes_. The anonymous medical data used in this notebook was obtained from 768 Pima women. It comprises 8 attributes that might be used to predict diabetes status (the 9th column in the dataset, which is the class to be predicted).\n",
        "\n",
        "The dataset has been removed from the UCI database, but is still widely available.\n",
        "\n",
        "We download this data as a csv (comma-separated variable) file (in `../data/pima-indians-diabetes.csv`)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f293a769",
      "metadata": {
        "lines_to_next_cell": 2,
        "tags": [
          "load"
        ]
      },
      "outputs": [],
      "source": [
        "dataDir = \"../data\"\n",
        "dataFile = dataDir + '/pima-indians-diabetes.csv'\n",
        "\n",
        "# See https://stackoverflow.com/a/82852\n",
        "import os.path\n",
        "if not os.path.isfile(dataFile):\n",
        "  import requests # Remember: you may need to install the requests module: conda install -c anaconda requests \n",
        "  \n",
        "  url = 'https://gist.github.com/chaityacshah/899a95deaf8b1930003ae93944fd17d7/raw/3d35de839da708595a444187e9f13237b51a2cbe/pima-indians-diabetes.csv'\n",
        "  r = requests.get(url)\n",
        "\n",
        "  # See https://stackoverflow.com/a/273227\n",
        "  os.makedirs(dataDir, exist_ok=True)\n",
        "  with open(dataFile, 'wb') as f:\n",
        "    f.write(r.content)\n",
        "    \n",
        "import pandas as pd\n",
        "pimaDf = pd.read_csv(dataFile)\n",
        "pimaDf.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c42c86de",
      "metadata": {},
      "source": [
        "While the existing predictor names are descriptive, they are cumbersome when used in models. Therefore, we replace them with simpler predictor names `predNames`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c305947c",
      "metadata": {
        "tags": [
          "viewData"
        ]
      },
      "outputs": [],
      "source": [
        "print(pimaDf.shape)\n",
        "predNames = ['NumPreg', 'PlasmaGlucose', 'DiastolicBP', 'SkinFold', 'SerumInsulin', 'BMI', 'PedFn', 'AgeYrs']\n",
        "className = 'DiabetesClass'\n",
        "colNames = predNames + [className]\n",
        "\n",
        "pimaDf.columns = colNames\n",
        "pimaDf.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c83af6a5",
      "metadata": {},
      "source": [
        "As can be seen, there are some predictor values that are unrealistic. For example, a `SerumInsulin` measurement of 0 is highly suspicious. similarly, the `SkinFold` test is often used to estimate body fat percentage, so a zero value is similarly unlikely. By contrast, `NumPreg` = 0 is plausible. Therefore, we make the assumption that when one of the other predictors takes a zero value, that the associated measurement is missing, but is assigned zero as a placeholder. In python, it is more meaningful to assign it to `None`, which is how python represents nulls."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "88eea37d",
      "metadata": {
        "tags": [
          "cleanupData"
        ]
      },
      "outputs": [],
      "source": [
        "nullablePredNames = predNames.copy()\n",
        "try:\n",
        "  nullablePredNames.remove('NumPreg')\n",
        "except ValueError:\n",
        "  pass\n",
        "\n",
        "filteredPimaDf = pimaDf.copy()\n",
        "\n",
        "for col in nullablePredNames:\n",
        "  filteredPimaDf.loc[pimaDf[col] == 0, col] = None\n",
        "\n",
        "filteredPimaDf.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1ffced9d",
      "metadata": {},
      "source": [
        "The next step, with any predictive model, is to partition the data into training and test subsets. We use the same approach that we used with the Iris Data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "670677e7",
      "metadata": {
        "lines_to_next_cell": 2,
        "tags": [
          "prepSplit"
        ]
      },
      "outputs": [],
      "source": [
        "X = filteredPimaDf[predNames]\n",
        "y = filteredPimaDf[['DiabetesClass']]\n",
        "\n",
        "# Import train_test_split function\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Split dataset into training and test sets\n",
        "def splitData(X, y):\n",
        "  testSize=0.33\n",
        "  randomState=5\n",
        "  X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=testSize, stratify=y, random_state=randomState)\n",
        "  return X_train, X_test, y_train, y_test\n",
        "\n",
        "X_train, X_test, y_train, y_test = splitData(X, y)\n",
        "print('Split {0} rows into train={1} and test={2} rows'.format(len(pimaDf.index), len(X_train.index), len(X_test.index)))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "dfb68308",
      "metadata": {},
      "source": [
        "## Naive Bayes from first principles\n",
        "\n",
        "The following python code was extracted from [How To Implement Naive Bayes From Scratch in Python](https://machinelearningmastery.com/naive-bayes-classifier-scratch-python/)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8b60cf13",
      "metadata": {
        "tags": [
          "ratioProbFunctions"
        ]
      },
      "outputs": [],
      "source": [
        "# Example of Naive Bayes implemented from Scratch in Python\n",
        "# Based on https://machinelearningmastery.com/naive-bayes-classifier-scratch-python/\n",
        "import math\n",
        "import numpy as np\n",
        "\n",
        "def separateByClass(dataset):\n",
        "  # Given a dataset, return a dict named _separated_\n",
        "  # The dict keys are the class labels\n",
        "  # The dict value for each key lis a list of the rows associated with that key\n",
        "  separated = {}\n",
        "  for index, row in dataset.iterrows():\n",
        "    # Note that row[-1] is the last element in the row and is the assigned class label\n",
        "    label = row[-1]\n",
        "    if (label not in separated):\n",
        "      # This is the first time we have met this class label, so create an empty list\n",
        "      separated[label] = []\n",
        "    separated[label].append(row)\n",
        "  return separated\n",
        "\n",
        "def summarize(dataset):\n",
        "  # Create (mean, stdev) tuples for each column in the given dataset, returning it as a list\n",
        "  summaries = [(np.mean(attribute), np.std(attribute)) for attribute in zip(*dataset)]\n",
        "  # remove the last element of the list, because we are not interested in the summarised class labels\n",
        "  del summaries[-1]\n",
        "  return summaries\n",
        "\n",
        "def summarizeByClass(dataset):\n",
        "  # Use separateByClass to generate the subsets of the rows by classLabel\n",
        "  # Then compute the list of (mean,stdev) tuples for each predictor, for each classLabel\n",
        "  separated = separateByClass(dataset)\n",
        "  summaries = {}\n",
        "  for classValue, instances in separated.items():\n",
        "    summaries[classValue] = summarize(instances)\n",
        "  return summaries\n",
        "\n",
        "def calculateProbability(x, mean, stdev):\n",
        "  # Compute the Gaussian(mean,stdev) probability evaluated at x\n",
        "  exponent = math.exp(-(math.pow(x-mean,2)/(2*math.pow(stdev,2))))\n",
        "  return (1 / (math.sqrt(2*math.pi) * stdev)) * exponent\n",
        "\n",
        "def calculateClassProbabilities(summaries, inputVector):\n",
        "  # Given the training summaries, and a row from the testSet,\n",
        "  # compute the probability of each of the class labels\n",
        "  probabilities = {}\n",
        "  # Loop over the classValues...\n",
        "  for classValue, classSummaries in summaries.items():\n",
        "    probabilities[classValue] = 1\n",
        "    # Loop over the summarised predictors\n",
        "    for i in range(len(classSummaries)):\n",
        "      mean, stdev = classSummaries[i]\n",
        "      # Note that x is the value of the associated predictor in the test instance\n",
        "      x = inputVector[i]\n",
        "      # Now calculate the Gaussian probability for this x\n",
        "      # We accumulate this predictor's probability by multiplying it with all the others\n",
        "      probabilities[classValue] *= calculateProbability(x, mean, stdev)\n",
        "  return probabilities\n",
        "      \n",
        "def predict(summaries, inputVector):\n",
        "  # Given the training summaries, and a row from the testSet,\n",
        "  # compute the probability of each of the class labels\n",
        "  probabilities = calculateClassProbabilities(summaries, inputVector)\n",
        "  bestLabel, bestProb = None, -1\n",
        "  # Now look for the bestLabel, which is associated with the highest probability\n",
        "  for classValue, probability in probabilities.items():\n",
        "    if bestLabel is None or probability > bestProb:\n",
        "      bestProb = probability\n",
        "      bestLabel = classValue\n",
        "  return bestLabel\n",
        "\n",
        "def getPredictions(summaries, testSet):\n",
        "  # Given (mean,stdev) summaries (by predictor, by classLabel) from the training data,\n",
        "  # compute predicted classLabels for each row in testSet, storing them in a list\n",
        "  predictions = []\n",
        "  for index, row in testSet.iterrows():\n",
        "    result = predict(summaries, row)\n",
        "    # Add the predicted classLabel to the predictions list\n",
        "    # Strictly, predictions should be a pandas series, so its index can match that of the testSet\n",
        "    predictions.append(result)\n",
        "  return predictions\n",
        "\n",
        "def getAccuracy(testSet, predictions):\n",
        "  # Compute the accuracy as a % of correct predictions over all predictions\n",
        "  correct = 0\n",
        "  i = 0\n",
        "  for index, row in testSet.iterrows():\n",
        "    # Accumate the cases where the assigned classLabel matches the predicted classLabel\n",
        "    if row[-1] == predictions[i]:\n",
        "      correct += 1\n",
        "    i += 1\n",
        "  return (correct/float(len(testSet))) * 100.0\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1f65b054",
      "metadata": {
        "tags": [
          "manualNBpredict"
        ]
      },
      "outputs": [],
      "source": [
        "# prepare model\n",
        "trainingSet = X_train.assign(DiabetesClass=y_train)\n",
        "summaries = summarizeByClass(trainingSet)\n",
        "# test model\n",
        "testSet = X_test.assign(DiabetesClass=y_test)\n",
        "predictions = getPredictions(summaries, testSet)\n",
        "accuracy = getAccuracy(testSet, predictions)\n",
        "print('Accuracy: {0}%'.format(accuracy))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e5dc96e8",
      "metadata": {},
      "source": [
        "As can be seen, the accuracy is approximately 65%.  We might be able to improve this by removing predictors having low prediction significance, computing functions of the predictors, etc., but such techniques are more easily done when using the scikit-learn implementation."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "259e30a9",
      "metadata": {},
      "source": [
        "## Using scikit-learn to compare Naive Bayes and SVM classifiers\n",
        "\n",
        "Needless to say, it is not necessary to program classifiers like Naive Bayes and SVM manually, because scikit-learn versions exist.\n",
        "\n",
        "Given the fact that there are so many predictors (8, though often the number of predictors (e.g., keywords for spam detection, or medium-resolution images for \"cat\" recognition....) can number tens of thousands), it is often advisable to look for a) correlations between predictors and b) correlations between predictors and the assigned class labels."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0f0b6906",
      "metadata": {
        "incorrectly_encoded_metadata": "tags=pimaCorr\"]"
      },
      "outputs": [],
      "source": [
        "corr = pimaDf.corr()\n",
        "corr"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b4ca6d1d",
      "metadata": {},
      "source": [
        "Note that some predictors appear to be moderately correlated with each other, notably corr(`PlasmaGlucose`,`serumInsulin`) = 0.33, which is quite high, but might be expected. We note that corr(`PlasmaGlucose`,`DiabetesClass`) = 0.47, which is the highest of all such correlations, therefore `plasmaGlucose` is quite highly correlated with diabetes state, as might be expected.\n",
        "\n",
        "We can also plot histograms of the predictor values, where we see that "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8b277fe2",
      "metadata": {
        "tags": [
          "pimaHiastogram"
        ]
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "pimaDf.hist(bins=50, figsize=(20, 15))\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "bc123f09",
      "metadata": {},
      "source": [
        "We can see the general distribution for each column and can see the effects of the missing values too. Apart from assigning such missing values to None, there is another way of accommodating such missing data, which is to impute values are statistically \"neutral\". We do this by assigning, when the predictor value is zero, the median of the remaining values of a predictor."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b8fabe09",
      "metadata": {
        "tags": [
          "imputeMissingValues"
        ]
      },
      "outputs": [],
      "source": [
        "adjustedPimaDf = pimaDf.copy()\n",
        "\n",
        "for col in nullablePredNames:\n",
        "  # Calculate the median value\n",
        "  medianVal = pimaDf.loc[pimaDf[col] != 0][col].median()\n",
        "  adjustedPimaDf.loc[pimaDf[col] == 0, col] = medianVal\n",
        "\n",
        "adjustedPimaDf.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "94e1b852",
      "metadata": {},
      "source": [
        "As before, we decide to split the dataset into training and test data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0fd60d95",
      "metadata": {
        "lines_to_next_cell": 2,
        "tags": [
          "splitAdjustedData"
        ]
      },
      "outputs": [],
      "source": [
        "X = adjustedPimaDf[predNames]\n",
        "y = adjustedPimaDf[['DiabetesClass']]\n",
        "\n",
        "X_train, X_test, y_train, y_test = splitData(X, y)\n",
        "print('Split {0} rows into train={1} and test={2} rows'.format(len(pimaDf.index), len(X_train.index), len(X_test.index)))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3174344f",
      "metadata": {},
      "source": [
        "One of the things that is noticeable is the fact that different predictors have different ranges of values, e.g., `NumPreg` is typically less than 10 while `SerumInsulin` is often greate than 100. `NaiveBayes` is based on probability so the different prediction values do not matter, other classifiers like SVM are sensitive to feature scaling. Luckily, scikit-learn has the ability to scale predictors so that they use a common scale."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d155454a",
      "metadata": {
        "tags": [
          "applyMinMaxScaler"
        ]
      },
      "outputs": [],
      "source": [
        "# Apply a scaler\n",
        "from sklearn.preprocessing import MinMaxScaler as Scaler\n",
        "\n",
        "scaler = Scaler()\n",
        "scaler.fit(X_train)\n",
        "X_train_scaled = scaler.transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "32e9cfc4",
      "metadata": {},
      "source": [
        "Now we can compare `NaiveBayes` and `SVM` classifiers. First we prepare for the comparison, which will use k-fold cross-validation rather than simply quoting a single accuracy score."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e28400a8",
      "metadata": {
        "incorrectly_encoded_metadata": "t5ags=[setupNBandSVC]"
      },
      "outputs": [],
      "source": [
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.svm import SVC\n",
        "\n",
        "# Import the slearn utility to compare algorithms\n",
        "from sklearn import model_selection\n",
        "\n",
        "# Prepare an array with the 2 algorithms\n",
        "models = []\n",
        "models.append(('NB', GaussianNB()))\n",
        "models.append(('SVC', SVC(gamma='auto')))\n",
        "\n",
        "# Prepare the configuration to run the test\n",
        "seed = 42\n",
        "results = []\n",
        "names = []\n",
        "nSplits = 10"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e7c9dfce",
      "metadata": {},
      "source": [
        "Now we run the comparison..."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "63135d32",
      "metadata": {
        "tags": [
          "compareNBandSVC"
        ]
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "# Fit the classifiers and output the crossVal results\n",
        "for name, model in models:\n",
        "    # We use k-fold cross validation, where 10% of the training data is held back each time \n",
        "    kfold = model_selection.KFold(n_splits=nSplits, random_state=seed, shuffle=True)\n",
        "    crossValResults = model_selection.cross_val_score(\n",
        "        model, X_train_scaled, np.ravel(y_train), cv=kfold, scoring='accuracy')\n",
        "    results.append(crossValResults)\n",
        "    names.append(name)\n",
        "    # Now print the results\n",
        "    print(\"%s: %f (%f)\" % (name, crossValResults.mean(), crossValResults.std()))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "dc4dbb6c",
      "metadata": {},
      "source": [
        "One of the advantages of k(=10)-fold cross-validation is that we get not just one estimate of accuracy, but 10 (in this case). Therefore we can look at how the accuracy is distributed."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b2866017",
      "metadata": {
        "tags": [
          "NB_SVCboxplot"
        ]
      },
      "outputs": [],
      "source": [
        "# boxplot algorithm comparison\n",
        "fig = plt.figure()\n",
        "fig.suptitle('Algorithm Comparison')\n",
        "ax = fig.add_subplot(111)\n",
        "plt.boxplot(results)\n",
        "ax.set_xticklabels(names)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0f46b632",
      "metadata": {},
      "source": [
        "Although it is not very obvious here, SVM generally outperforms Naive Bayes."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "75fda8cb",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Import scikit-learn metrics module for accuracy calculation\n",
        "from sklearn.metrics import confusion_matrix, accuracy_score, classification_report\n",
        "\n",
        "def showDiagnostics(y, y_pred):\n",
        "  # Model Accuracy, how often is the classifier correct?\n",
        "  print(\"Accuracy:\",accuracy_score(y, y_pred))\n",
        "  print(\"Confusion Matrix:\")\n",
        "  print(confusion_matrix(y, y_pred))\n",
        "  print(\"Classification Report:\")\n",
        "  print(classification_report(y, y_pred, digits=3))\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "08af16f4",
      "metadata": {
        "tags": [
          "NBdiagnostics"
        ]
      },
      "outputs": [],
      "source": [
        "# Create a Naive Bayes Classifier\n",
        "clf=GaussianNB()\n",
        "\n",
        "# Train the model using the training sets y_pred=clf.predict(X_test)\n",
        "clf.fit(X_train_scaled,np.ravel(y_train))\n",
        "\n",
        "# prediction on test set\n",
        "y_pred=clf.predict(X_test_scaled)\n",
        "\n",
        "showDiagnostics(y_test, y_pred)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2f9000d6",
      "metadata": {
        "tags": [
          "SVMdiagnostics"
        ]
      },
      "outputs": [],
      "source": [
        "# Create a SVM Classifier\n",
        "clf=SVC(gamma='auto')\n",
        "\n",
        "# Train the model using the training sets y_pred=clf.predict(X_test)\n",
        "clf.fit(X_train_scaled,np.ravel(y_train))\n",
        "\n",
        "# prediction on test set\n",
        "y_pred=clf.predict(X_test_scaled)\n",
        "\n",
        "showDiagnostics(y_test, y_pred)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0de614ed",
      "metadata": {},
      "source": [
        "The traditional \"compare assigned and predicted class labels for the test set\" gives results that are consistent with the k-fold cross-validation results earlier."
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
