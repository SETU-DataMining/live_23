{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a6fc0d96",
   "metadata": {},
   "source": [
    "# Introduction to NLTK\n",
    "\n",
    "This notebook is designed to be used alongside the book _Natural Language Processing with Python: Analyzing Text with the Natural Language Toolkit_, written by Steven Bird, Ewan Klein, and Edward Loper of Stanford University, who developed NLTK.\n",
    "\n",
    "This notebook is based on the following sources:\n",
    "\n",
    "- [NLTK book, chapter 1](https://www.nltk.org/book/ch01.html)\n",
    "- [NLTK tutorial](https://www.analyticsvidhya.com/blog/2021/07/nltk-a-beginners-hands-on-guide-to-natural-language-processing/)\n",
    "- [Practice parsing text in NLP with Python](https://opensource.com/article/20/8/intro-python-nltk)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44a27c43",
   "metadata": {},
   "source": [
    "First install nltk using\n",
    "\n",
    "    conda install -c anaconda nltk\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f1b7be04",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import nltk"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c4f162a",
   "metadata": {},
   "source": [
    "You now need to select what corpora (plural of corpus!) and packages you require. For this notebook, it is sufficient to select just the \"book\" identifier. After running this, it is better to comment out the next line so it is not run again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e7bec532",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#nltk.download()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "505cfc89",
   "metadata": {},
   "source": [
    "## Assign some text and tokenise it\n",
    "\n",
    "First we just check that we can tokenize a short piece of text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "149b7ef0",
   "metadata": {
    "tags": [
     "define_maSpeech"
    ]
   },
   "outputs": [],
   "source": [
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "\n",
    "maSpeech = \"\"\"Friends, Romans, countrymen, lend me your ears;\n",
    "I come to bury Caesar, not to praise him.\n",
    "The evil that men do lives after them;\n",
    "The good is oft interred with their bones;\n",
    "So let it be with Caesar.\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3aded187",
   "metadata": {},
   "source": [
    "First we split the text into sentences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a554675c",
   "metadata": {
    "tags": [
     "sent_tokenize_maSpeech"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Friends, Romans, countrymen, lend me your ears;\\nI come to bury Caesar, not to praise him.', 'The evil that men do lives after them;\\nThe good is oft interred with their bones;\\nSo let it be with Caesar.']\n"
     ]
    }
   ],
   "source": [
    "print(sent_tokenize(maSpeech))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22737317",
   "metadata": {},
   "source": [
    "Now we split the text into words. Note that punctuation elements (like commas and full stops) are also treated as \"word\" tokens."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3514f9fd",
   "metadata": {
    "tags": [
     "word_tokenize_maSpeech"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Friends', ',', 'Romans', ',', 'countrymen', ',', 'lend', 'me', 'your', 'ears', ';', 'I', 'come', 'to', 'bury', 'Caesar', ',', 'not', 'to', 'praise', 'him', '.', 'The', 'evil', 'that', 'men', 'do', 'lives', 'after', 'them', ';', 'The', 'good', 'is', 'oft', 'interred', 'with', 'their', 'bones', ';', 'So', 'let', 'it', 'be', 'with', 'Caesar', '.']\n"
     ]
    }
   ],
   "source": [
    "print(word_tokenize(maSpeech))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da6615ba",
   "metadata": {},
   "source": [
    "## Stage 1: Remove punctuation and make the text lower case\n",
    "\n",
    "We use python's _regular expression_ library `re` to exclude non-alphanumeric characters, such as punctuation, and python's inbuilt `lower()`fnction to convert all alphabetic characters to lower case."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dda0998d",
   "metadata": {
    "tags": [
     "removePuncLower"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "friends  romans  countrymen  lend me your ears  i come to bury caesar  not to praise him  the evil that men do lives after them  the good is oft interred with their bones  so let it be with caesar \n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "text = re.sub(r\"[^a-zA-Z0-9]\", \" \", maSpeech.lower())\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e66a0a67",
   "metadata": {},
   "source": [
    "Now we can split the lower case text by spaces and we just get a list of those words, without punctuation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b3db34a5",
   "metadata": {
    "tags": [
     "splitMaSpeech"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Friends,', 'Romans,', 'countrymen,', 'lend', 'me', 'your', 'ears;', 'I', 'come', 'to', 'bury', 'Caesar,', 'not', 'to', 'praise', 'him.', 'The', 'evil', 'that', 'men', 'do', 'lives', 'after', 'them;', 'The', 'good', 'is', 'oft', 'interred', 'with', 'their', 'bones;', 'So', 'let', 'it', 'be', 'with', 'Caesar.']\n"
     ]
    }
   ],
   "source": [
    "words = maSpeech.split()\n",
    "print(words)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b4d7588",
   "metadata": {},
   "source": [
    "## Stage 2: Remove stopwords\n",
    "\n",
    "There are many words in the English language that do not add much information by themselves. As such they can usually be removed, as they are just \"noise\" added to the more useful words that carry most of the meaning of the text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2350013e",
   "metadata": {
    "incorrectly_encoded_metadata": "tags=[removeStopWords\"]"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', \"you're\", \"you've\", \"you'll\", \"you'd\", 'your', 'yours', 'yourself', 'yourselves', 'he', 'him', 'his', 'himself', 'she', \"she's\", 'her', 'hers', 'herself', 'it', \"it's\", 'its', 'itself', 'they', 'them', 'their', 'theirs', 'themselves', 'what', 'which', 'who', 'whom', 'this', 'that', \"that'll\", 'these', 'those', 'am', 'is', 'are', 'was', 'were', 'be', 'been', 'being', 'have', 'has', 'had', 'having', 'do', 'does', 'did', 'doing', 'a', 'an', 'the', 'and', 'but', 'if', 'or', 'because', 'as', 'until', 'while', 'of', 'at', 'by', 'for', 'with', 'about', 'against', 'between', 'into', 'through', 'during', 'before', 'after', 'above', 'below', 'to', 'from', 'up', 'down', 'in', 'out', 'on', 'off', 'over', 'under', 'again', 'further', 'then', 'once', 'here', 'there', 'when', 'where', 'why', 'how', 'all', 'any', 'both', 'each', 'few', 'more', 'most', 'other', 'some', 'such', 'no', 'nor', 'not', 'only', 'own', 'same', 'so', 'than', 'too', 'very', 's', 't', 'can', 'will', 'just', 'don', \"don't\", 'should', \"should've\", 'now', 'd', 'll', 'm', 'o', 're', 've', 'y', 'ain', 'aren', \"aren't\", 'couldn', \"couldn't\", 'didn', \"didn't\", 'doesn', \"doesn't\", 'hadn', \"hadn't\", 'hasn', \"hasn't\", 'haven', \"haven't\", 'isn', \"isn't\", 'ma', 'mightn', \"mightn't\", 'mustn', \"mustn't\", 'needn', \"needn't\", 'shan', \"shan't\", 'shouldn', \"shouldn't\", 'wasn', \"wasn't\", 'weren', \"weren't\", 'won', \"won't\", 'wouldn', \"wouldn't\"]\n",
      "['Friends,', 'Romans,', 'countrymen,', 'lend', 'ears;', 'I', 'come', 'bury', 'Caesar,', 'praise', 'him.', 'The', 'evil', 'men', 'lives', 'them;', 'The', 'good', 'oft', 'interred', 'bones;', 'So', 'let', 'Caesar.']\n"
     ]
    }
   ],
   "source": [
    "from nltk.corpus import stopwords\n",
    "print(stopwords.words(\"english\"))\n",
    "\n",
    "# Remove stop words, using a list comprehension\n",
    "filteredWords = [w for w in words if w not in stopwords.words(\"english\")]\n",
    "print(filteredWords)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "568ef4b7",
   "metadata": {},
   "source": [
    "Note that many of the words have been removed, but those that are left are the \"interesting\" ones."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "986a52df",
   "metadata": {},
   "source": [
    "## Stage 3a: Stemming\n",
    "\n",
    "Some words are essentially similar, e.g., \"friend\" and \"friends\" or \"come\" and \"came\". In NLP terms, each such pair is derived from a \"stem\" word. NLTK offers Porter, Lancaster and Snowball stemmers, which help to standardise the text as follows. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1e02d5f4",
   "metadata": {
    "tags": [
     "applyStemmer"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['friends,', 'romans,', 'countrymen,', 'lend', 'ears;', 'i', 'come', 'buri', 'caesar,', 'prais', 'him.', 'the', 'evil', 'men', 'live', 'them;', 'the', 'good', 'oft', 'inter', 'bones;', 'so', 'let', 'caesar.']\n"
     ]
    }
   ],
   "source": [
    "from nltk.stem.porter import PorterStemmer\n",
    "# Reduce words to their stems\n",
    "porterStemmed = [PorterStemmer().stem(w) for w in filteredWords]\n",
    "print(porterStemmed)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4668a867",
   "metadata": {},
   "source": [
    "Note that some word stems are not quite right, e.g., \"buri\" should be \"bury\". The error is because the Porter stemming rule was to remove \"ed\" from the end of the word, where it is found. This rule might work in many cases, but there are exceptions, as here."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d8f35f5",
   "metadata": {},
   "source": [
    "# Stage 3b: Lemmatisation\n",
    "\n",
    "An alternative approach, that is often more reliable (though the need to lookup a language-specific dictionary can make it run slowly with large amounts of text), is called lemmatisation. A _lemma_ is a candidate root that is obtained by looking up a database of real words. We try this as an alternative standardisation technique."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8da81965",
   "metadata": {
    "tags": [
     "applyLemmatisation"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Friends,', 'Romans,', 'countrymen,', 'lend', 'ears;', 'I', 'come', 'bury', 'Caesar,', 'praise', 'him.', 'The', 'evil', 'men', 'life', 'them;', 'The', 'good', 'oft', 'interred', 'bones;', 'So', 'let', 'Caesar.']\n"
     ]
    }
   ],
   "source": [
    "#nltk.download('omw-1.4')\n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "# Reduce words to their root form\n",
    "wnLemmed = [WordNetLemmatizer().lemmatize(w) for w in filteredWords]\n",
    "print(wnLemmed)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f67a31c",
   "metadata": {},
   "source": [
    "Note that lemmatisation has generally performed better, but it failed to notice that \"interred\" is the past tense of \"inter\" (to bury), whereas the Porter stemmer correctly applied a rule that transformed \"interred\" to \"inter\"."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c35c8548",
   "metadata": {},
   "source": [
    "## Next step - analytics\n",
    "\n",
    "Now that we have preprocessed the words from our text, we can generate simple counts, showing how the original set was changed by the 3 stages of preprocessing above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2b1c05ae",
   "metadata": {
    "tags": [
     "outputMaSpeechWordSummary"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of words without punctuation 38\n",
      "Number of words without punctuation and stopwords 24\n",
      "Number of such words following stemming 24\n",
      "Number of such words following lemmatisation 24\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of words without punctuation {}\".format(len(words)))\n",
    "print(\"Number of words without punctuation and stopwords {}\".format(len(filteredWords)))\n",
    "print(\"Number of such words following stemming {}\".format(len(porterStemmed)))\n",
    "print(\"Number of such words following lemmatisation {}\".format(len(wnLemmed)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6edbf2af",
   "metadata": {},
   "source": [
    "Now we count unique words. Python provides a set datatype, which has the property that its elements are distinct. So adding a list of elements to a set essentially removes repeats, so each element appears only once."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d0e2b4d4",
   "metadata": {
    "tags": [
     "outputMaSpeechDistinctWordSummary"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of distinct words without punctuation 35\n",
      "Number of distinct words without punctuation and stopwords 23\n",
      "Number of such distinct words following stemming 23\n",
      "Number of such distinct words following lemmatisation 23\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of distinct words without punctuation {}\".format(len(set(words))))\n",
    "print(\"Number of distinct words without punctuation and stopwords {}\".format(len(set(filteredWords))))\n",
    "print(\"Number of such distinct words following stemming {}\".format(len(set(porterStemmed))))\n",
    "print(\"Number of such distinct words following lemmatisation {}\".format(len(set(wnLemmed))))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e1d06bc",
   "metadata": {},
   "source": [
    "## Loading larger amounts of data\n",
    "\n",
    "We have already installed several collections of text (books, speeches, blogs, posts, newspaper articles, etc.). To show more features of NLTK, we need to load these in memory and to analyse their text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "39238fd1",
   "metadata": {
    "tags": [
     "importCorpora"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** Introductory Examples for the NLTK Book ***\n",
      "Loading text1, ..., text9 and sent1, ..., sent9\n",
      "Type the name of the text or sentence to view it.\n",
      "Type: 'texts()' or 'sents()' to list the materials.\n",
      "text1: Moby Dick by Herman Melville 1851\n",
      "text2: Sense and Sensibility by Jane Austen 1811\n",
      "text3: The Book of Genesis\n",
      "text4: Inaugural Address Corpus\n",
      "text5: Chat Corpus\n",
      "text6: Monty Python and the Holy Grail\n",
      "text7: Wall Street Journal\n",
      "text8: Personals Corpus\n",
      "text9: The Man Who Was Thursday by G . K . Chesterton 1908\n"
     ]
    }
   ],
   "source": [
    "from nltk.book import *"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fbedf46",
   "metadata": {},
   "source": [
    "`texts()` prints the names and authorship of each of the texts and `sents()` prints the first sentence of each text."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63a9ff0c",
   "metadata": {},
   "source": [
    "## Concordance analysis\n",
    "\n",
    "Noting that \"text1\" refers to \"Moby Dick\", we can look at the concordances of a key word like \"monstrous\", by viewing it in context."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b2c8ae5f",
   "metadata": {
    "tags": [
     "concordance1"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Displaying 11 of 11 matches:\n",
      "ong the former , one was of a most monstrous size . ... This came towards us , \n",
      "ON OF THE PSALMS . \" Touching that monstrous bulk of the whale or ork we have r\n",
      "ll over with a heathenish array of monstrous clubs and spears . Some were thick\n",
      "d as you gazed , and wondered what monstrous cannibal and savage could ever hav\n",
      "that has survived the flood ; most monstrous and most mountainous ! That Himmal\n",
      "they might scout at Moby Dick as a monstrous fable , or still worse and more de\n",
      "th of Radney .'\" CHAPTER 55 Of the Monstrous Pictures of Whales . I shall ere l\n",
      "ing Scenes . In connexion with the monstrous pictures of whales , I am strongly\n",
      "ere to enter upon those still more monstrous stories of them which are to be fo\n",
      "ght have been rummaged out of this monstrous cabinet there is no telling . But \n",
      "of Whale - Bones ; for Whales of a monstrous size are oftentimes cast up dead u\n"
     ]
    }
   ],
   "source": [
    "text1.concordance(\"monstrous\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8a60338",
   "metadata": {},
   "source": [
    "It is obvious from these 11 examples that the author (Herman Melville) uses \"monstrous\" in the sense of \"large\", \"imposing\" and \"dangerous\".\n",
    "\n",
    "Famously, the Book of Genesis often refers to long-lived individuals, so concordance analysis can help to select sentences relating to this topic."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c42deac6",
   "metadata": {
    "tags": [
     "concordance3"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Displaying 25 of 38 matches:\n",
      "ay when they were created . And Adam lived an hundred and thirty years , and be\n",
      "ughters : And all the days that Adam lived were nine hundred and thirty yea and\n",
      "nd thirty yea and he died . And Seth lived an hundred and five years , and bega\n",
      "ve years , and begat Enos : And Seth lived after he begat Enos eight hundred an\n",
      "welve years : and he died . And Enos lived ninety years , and begat Cainan : An\n",
      " years , and begat Cainan : And Enos lived after he begat Cainan eight hundred \n",
      "ive years : and he died . And Cainan lived seventy years and begat Mahalaleel :\n",
      "rs and begat Mahalaleel : And Cainan lived after he begat Mahalaleel eight hund\n",
      "years : and he died . And Mahalaleel lived sixty and five years , and begat Jar\n",
      "s , and begat Jared : And Mahalaleel lived after he begat Jared eight hundred a\n",
      "and five yea and he died . And Jared lived an hundred sixty and two years , and\n",
      "o years , and he begat Eno And Jared lived after he begat Enoch eight hundred y\n",
      " and two yea and he died . And Enoch lived sixty and five years , and begat Met\n",
      " ; for God took him . And Methuselah lived an hundred eighty and seven years , \n",
      " , and begat Lamech . And Methuselah lived after he begat Lamech seven hundred \n",
      "nd nine yea and he died . And Lamech lived an hundred eighty and two years , an\n",
      "ch the LORD hath cursed . And Lamech lived after he begat Noah five hundred nin\n",
      "naan shall be his servant . And Noah lived after the flood three hundred and fi\n",
      "xad two years after the flo And Shem lived after he begat Arphaxad five hundred\n",
      "at sons and daughters . And Arphaxad lived five and thirty years , and begat Sa\n",
      "ars , and begat Salah : And Arphaxad lived after he begat Salah four hundred an\n",
      "begat sons and daughters . And Salah lived thirty years , and begat Eber : And \n",
      "y years , and begat Eber : And Salah lived after he begat Eber four hundred and\n",
      " begat sons and daughters . And Eber lived four and thirty years , and begat Pe\n",
      "y years , and begat Peleg : And Eber lived after he begat Peleg four hundred an\n"
     ]
    }
   ],
   "source": [
    "text3.concordance(\"lived\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc477d2c",
   "metadata": {},
   "source": [
    "Each of the characters seemed to have lived for a long time....\n",
    "\n",
    "Returning to \"monstrous\" and _Moby Dick_, it is also informative to see what other words are used by the author in a similar context. This can be done with the following code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0e7f5256",
   "metadata": {
    "tags": [
     "similar1"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "true contemptible christian abundant few part mean careful puzzled\n",
      "mystifying passing curious loving wise doleful gamesome singular\n",
      "delightfully perilous fearless\n"
     ]
    }
   ],
   "source": [
    "text1.similar(\"monstrous\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "954f8a27",
   "metadata": {},
   "source": [
    "Given our understanding of language, we can see some of these as near-synonyms of \"monstrous\" as used by the author, although the others seem unrelated to that meaning."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5656bea0",
   "metadata": {},
   "source": [
    "Some corpora have a natural temporal ordering. For example, the addresses to Congress are ordered so that more recent speeches are found at the end of the corpus. Consequently, it is interesting to see how the popularity of certain terms has changed over time. Similar temporal patterns might be expected in news reports and social media posts, as words like \"covid\" or \"Kardashian\" rise and fall in importance. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "25deafd2",
   "metadata": {
    "tags": [
     "dispersionPlot"
    ]
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "text4.dispersion_plot([\"citizens\", \"democracy\", \"freedom\", \"duties\", \"America\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d914d0d9",
   "metadata": {},
   "source": [
    "It is noticeable that \"democracy\", \"freedom\" and \"America\" are much more common in recent speeches, while \"duties\" has become less common."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "734aedfc",
   "metadata": {},
   "source": [
    "Returning to the first text (Moby Dick), it is interesting to view the frequency distribution of words.  NLTK provides a function for that purpose. Rather than view all words, we just choose those that occur most frequently."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "90c335ba",
   "metadata": {
    "tags": [
     "fdist1"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(',', 18713),\n",
       " ('the', 13721),\n",
       " ('.', 6862),\n",
       " ('of', 6536),\n",
       " ('and', 6024),\n",
       " ('a', 4569),\n",
       " ('to', 4542),\n",
       " (';', 4072),\n",
       " ('in', 3916),\n",
       " ('that', 2982),\n",
       " (\"'\", 2684),\n",
       " ('-', 2552),\n",
       " ('his', 2459),\n",
       " ('it', 2209),\n",
       " ('I', 2124),\n",
       " ('s', 1739),\n",
       " ('is', 1695),\n",
       " ('he', 1661),\n",
       " ('with', 1659),\n",
       " ('was', 1632),\n",
       " ('as', 1620),\n",
       " ('\"', 1478),\n",
       " ('all', 1462),\n",
       " ('for', 1414),\n",
       " ('this', 1280),\n",
       " ('!', 1269),\n",
       " ('at', 1231),\n",
       " ('by', 1137),\n",
       " ('but', 1113),\n",
       " ('not', 1103),\n",
       " ('--', 1070),\n",
       " ('him', 1058),\n",
       " ('from', 1052),\n",
       " ('be', 1030),\n",
       " ('on', 1005),\n",
       " ('so', 918),\n",
       " ('whale', 906),\n",
       " ('one', 889),\n",
       " ('you', 841),\n",
       " ('had', 767)]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fdist1 = FreqDist(text1)\n",
    "fdist1.most_common(40)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2848287",
   "metadata": {},
   "source": [
    "As you can see, most of the \"words\" are either punctuation or stop words, but interesting words like \"whale\" make it into the list."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7f88dfc",
   "metadata": {},
   "source": [
    "## Bi-grams and their collocations\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f3ef6b4",
   "metadata": {},
   "source": [
    "While it is interesting to look at word counts, the difficulty is that words on their own are difficult to interpret. This is the reason why text analysis often considers _bi-grams_, which are pairs of adjacent words, or even _tri-grams_ which are 3 words together in a longer phrase.\n",
    "\n",
    "By choosing to examine the most frequently occurring bigrams, it is much easier to get a sense of the topics of interest in the text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f3d541bc",
   "metadata": {
    "tags": [
     "fdist2"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[((',', 'and'), 2607),\n",
       " (('of', 'the'), 1847),\n",
       " ((\"'\", 's'), 1737),\n",
       " (('in', 'the'), 1120),\n",
       " ((',', 'the'), 908),\n",
       " ((';', 'and'), 853),\n",
       " (('to', 'the'), 712),\n",
       " (('.', 'But'), 596),\n",
       " ((',', 'that'), 584),\n",
       " (('.', '\"'), 557),\n",
       " ((',', 'as'), 523),\n",
       " ((',', 'I'), 461),\n",
       " ((',', 'he'), 446),\n",
       " (('from', 'the'), 428),\n",
       " ((',', 'in'), 402),\n",
       " (('of', 'his'), 371),\n",
       " (('the', 'whale'), 369),\n",
       " (('.', 'The'), 369),\n",
       " (('and', 'the'), 357),\n",
       " ((';', 'but'), 340)]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from collections import Counter\n",
    "fdist2 = Counter(list(bigrams(text1)))\n",
    "fdist2.most_common(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6426697",
   "metadata": {},
   "source": [
    "Note that combinations of stopwords and punctuation dominate this list of bigrams. As an exercise: you are advised to __preprocess the text (removing punctuation and stopwards and normalising the remaining text) so that the list of bigrams is more \"interesting\"__.\n",
    "\n",
    "A further refinement is to consider only those bigrams that are frequent _and_ this would not be expected from the frequency of the individual words. That is, if two words occur frequently, it is also likely that the associated bigram also appears frequently; this is not particularly interesting. The bigrams of greatest interest might be those that are \"surprising\" because they occur frequently but their individual words are not particularly frequent. Such bigrams are called _collocations_ in the NLP community.\n",
    "\n",
    "Applying this to the speeches made to the US Congress, we see"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ea4d2c8c",
   "metadata": {
    "tags": [
     "collocations4"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "United States; fellow citizens; years ago; four years; Federal\n",
      "Government; General Government; American people; Vice President; God\n",
      "bless; Chief Justice; one another; fellow Americans; Old World;\n",
      "Almighty God; Fellow citizens; Chief Magistrate; every citizen; Indian\n",
      "tribes; public debt; foreign nations\n"
     ]
    }
   ],
   "source": [
    "text4.collocations()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "521e8999",
   "metadata": {},
   "source": [
    "Knowing the preoccupations of US politicians, those two-word phrases should not be surprising. Perhaps the one that stands out is \"Indian tribes\", which probably dates back to the time when the US was expanding westwards and encountered resistance from Native Americans.\n",
    "\n",
    "Another text corpus that reveals interesting/amusing bigrams is text8, which is drawn from personal ads, see below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "0ffd745c",
   "metadata": {
    "tags": [
     "collocations8"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "would like; medium build; social drinker; quiet nights; non smoker;\n",
      "long term; age open; Would like; easy going; financially secure; fun\n",
      "times; similar interests; Age open; weekends away; poss rship; well\n",
      "presented; never married; single mum; permanent relationship; slim\n",
      "build\n"
     ]
    }
   ],
   "source": [
    "text8.collocations()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86345297",
   "metadata": {},
   "source": [
    "Perhaps it is a pity that we do not have an equivalent corpus of property advertisements, or of wine reviews, each of which has its own \"jargon\" :-)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "061f615f",
   "metadata": {},
   "source": [
    "### Collocations applied to \"Pride and Prejudice\"\n",
    "\n",
    "In the following example, we obtain the plain text version of _Pride and Prejudice_ by Jane Austen from Project Gutenberg, to show that it is easy to apply NLTK to text you provide, not just to corpora supplied with NLTK itself.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c89286d8",
   "metadata": {
    "tags": [
     "getPrideAndPrejudice"
    ]
   },
   "outputs": [],
   "source": [
    "import urllib.request\n",
    "\n",
    "# Download text and decode\n",
    "url = \"http://www.gutenberg.org/files/1342/1342-0.txt\"\n",
    "text = urllib.request.urlopen(url).read().decode()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "19ed1a53",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "﻿The Project Gutenberg eBook of Pride and Prejudice, by Jane Austen\n",
      "\n",
      "This eBook is for the use of anyone anywhere in the United States and\n",
      "most other parts of the world at no cost and with almost no restrictions\n",
      "whatsoever. You may copy it, give it away or re-use it under the terms\n",
      "of the Project Gutenberg License included with this eBook or online at\n",
      "www.gutenberg.org. If you are not located in the United States, you\n",
      "will have to check the laws of the country where you are located before\n",
      "using this eBook.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "print(os.linesep.join(text.split(os.linesep)[:10]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c11346af",
   "metadata": {
    "tags": []
   },
   "source": [
    "First we preprocess the data, in the usual way:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f291a9b8",
   "metadata": {
    "tags": [
     "preprocessP&P"
    ]
   },
   "outputs": [],
   "source": [
    "# Change to lower case and tokenise\n",
    "from nltk.tokenize import word_tokenize\n",
    "lcWords = word_tokenize(text.lower())\n",
    "\n",
    "# Remove stopwords\n",
    "from nltk.corpus import stopwords\n",
    "stopWords = stopwords.words('english')\n",
    "filteredWords = [w for w in lcWords if w not in stopWords]\n",
    "\n",
    "# Remove punctuations, including an additional quote types\n",
    "import string\n",
    "punctuationMarks = list(string.punctuation)\n",
    "words = [w for w in filteredWords if (w not in punctuationMarks) and (w not in ('“','”','’'))]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "170bf71e",
   "metadata": {},
   "source": [
    "For a change, we will look at the trigrams in the text, and show how to configure the collocation finder to use non-default settings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "671e9aca",
   "metadata": {
    "tags": [
     "trigramsP&P"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trigrams: [('late', 'mr.', 'darcy'), ('mr.', 'darcy', 'returned'), ('saw', 'mr.', 'darcy'), ('friend', 'mr.', 'darcy'), ('mr.', 'darcy', 'looked'), ('mr.', 'darcy', 'walked'), ('civility', 'mr.', 'darcy'), ('surprised', 'mr.', 'darcy'), ('mr.', 'darcy', 'made'), ('mr.', 'darcy', 'would'), ('said', 'mr.', 'darcy'), ('mr.', 'darcy', 'steward'), ('mr.', 'darcy', 'smiled'), ('mr.', 'darcy', 'sent'), ('mr.', 'darcy', 'called'), ('mr.', 'darcy', 'devoted'), ('overheard', 'mr.', 'darcy'), ('resemblance', 'mr.', 'darcy'), ('mr.', 'darcy', '_he_'), ('mr.', 'darcy', 'took'), ('mr.', 'darcy', 'seemed'), ('mr.', 'darcy', 'explanation'), ('mr.', 'darcy', 'expressed'), ('would', 'mr.', 'darcy'), ('recollection', 'mr.', 'darcy'), ('towards', 'mr.', 'darcy'), ('engaged', 'mr.', 'darcy'), ('class', 'mr.', 'darcy'), ('darcy—that', 'mr.', 'darcy'), ('deaden', 'mr.', 'darcy'), ('explanation.', 'mr.', 'darcy'), ('frighten', 'mr.', 'darcy'), ('inmate', 'mr.', 'darcy'), ('justification', 'mr.', 'darcy'), ('levelled', 'mr.', 'darcy'), ('mistook', 'mr.', 'darcy'), ('mr.', 'darcy', 'believes'), ('mr.', 'darcy', 'bequeathed'), ('mr.', 'darcy', 'corroborated'), ('mr.', 'darcy', 'eyeing')]\n"
     ]
    }
   ],
   "source": [
    "# Trigrams\n",
    "from nltk.collocations import TrigramCollocationFinder\n",
    "from nltk.metrics import TrigramAssocMeasures\n",
    "trigram_collocation = TrigramCollocationFinder.from_words(words)\n",
    "# Top 40 most grequently occurring collocations\n",
    "print(\"Trigrams:\", trigram_collocation.nbest(TrigramAssocMeasures.likelihood_ratio, 40))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c31a330d",
   "metadata": {},
   "source": [
    "There are no prizes for guessing the name of one of the main characters in the novel!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a65a4631",
   "metadata": {},
   "source": [
    "## Parsing\n",
    "\n",
    "So far, we have focused on lexical aspects, from documents to sentences to phrases to words.\n",
    "\n",
    "However text is not just a combination of these elements. Languages have syntax rules that govern how words are put together.  The syntax rules for a language are termed its _grammar_. Each language has its own grammar. Understanding the syntax of the language is a necessary step in being able to derive the meaning of text written in that language.\n",
    "\n",
    "Apart from the language production rules that are essential for understanding the structure of a document, syntax analysis also helps to provide additional, context-specific metadata for each word or phrase. This metadata can be added to the text by means of a process called _part of speech (POS) tagging_.\n",
    "\n",
    "The purpose of parsing is to apply the grammar rules to recognise the structure in each text unit (usually a sentence) and to tag elements of that text with their POS label, as decided by the parser."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da0b3440",
   "metadata": {},
   "source": [
    "Returning to the opening lines of Mark Antony's speech, we can ask NLTK to tag each word with its POS label. Note that POS tagging is applied to the _original_ text, not to a standardised version because capitalisation, punctuation, plural forms etc. are needed to parse the text correctly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "11a5e80d",
   "metadata": {},
   "outputs": [],
   "source": [
    "words = word_tokenize(maSpeech)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f06e74a",
   "metadata": {},
   "source": [
    "Using the normal rules of English grammar, we can tag the words with their POS labels. Of course, if a different language was used, say Hindi, the tagger needs to be told to use Hindi grammar instead of English grammar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "60c7d1ed",
   "metadata": {
    "tags": [
     "posTag"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('Friends', 'NNS'), (',', ','), ('Romans', 'NNPS'), (',', ','), ('countrymen', 'NNS'), (',', ','), ('lend', 'VB'), ('me', 'PRP'), ('your', 'PRP$'), ('ears', 'NNS'), (';', ':'), ('I', 'PRP'), ('come', 'VBP'), ('to', 'TO'), ('bury', 'VB'), ('Caesar', 'NNP'), (',', ','), ('not', 'RB'), ('to', 'TO'), ('praise', 'VB'), ('him', 'PRP'), ('.', '.'), ('The', 'DT'), ('evil', 'JJ'), ('that', 'IN'), ('men', 'NNS'), ('do', 'VBP'), ('lives', 'NNS'), ('after', 'IN'), ('them', 'PRP'), (';', ':'), ('The', 'DT'), ('good', 'JJ'), ('is', 'VBZ'), ('oft', 'JJ'), ('interred', 'VBN'), ('with', 'IN'), ('their', 'PRP$'), ('bones', 'NNS'), (';', ':'), ('So', 'NNP'), ('let', 'VB'), ('it', 'PRP'), ('be', 'VB'), ('with', 'IN'), ('Caesar', 'NNP'), ('.', '.')]\n"
     ]
    }
   ],
   "source": [
    "pos_tagged_text = nltk.pos_tag(words)\n",
    "print(pos_tagged_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4600b12f",
   "metadata": {},
   "source": [
    "The POS codes are [defined by linguists at the University of Pennsylvania](https://www.ling.upenn.edu/courses/Fall_2003/ling001/penn_treebank_pos.html) and are useful for all natural languages. It is convenient to display each word, with its tag and description, using the following code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "13834e25",
   "metadata": {
    "tags": [
     "posTag2"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Friends :\n",
      "NNS: noun, common, plural\n",
      "    undergraduates scotches bric-a-brac products bodyguards facets coasts\n",
      "    divestitures storehouses designs clubs fragrances averages\n",
      "    subjectivists apprehensions muses factory-jobs ...\n",
      ", :\n",
      ",: comma\n",
      "    ,\n",
      "Romans :\n",
      "NNPS: noun, proper, plural\n",
      "    Americans Americas Amharas Amityvilles Amusements Anarcho-Syndicalists\n",
      "    Andalusians Andes Andruses Angels Animals Anthony Antilles Antiques\n",
      "    Apache Apaches Apocrypha ...\n",
      ", :\n",
      ",: comma\n",
      "    ,\n",
      "countrymen :\n",
      "NNS: noun, common, plural\n",
      "    undergraduates scotches bric-a-brac products bodyguards facets coasts\n",
      "    divestitures storehouses designs clubs fragrances averages\n",
      "    subjectivists apprehensions muses factory-jobs ...\n",
      ", :\n",
      ",: comma\n",
      "    ,\n",
      "lend :\n",
      "VB: verb, base form\n",
      "    ask assemble assess assign assume atone attention avoid bake balkanize\n",
      "    bank begin behold believe bend benefit bevel beware bless boil bomb\n",
      "    boost brace break bring broil brush build ...\n",
      "me :\n",
      "PRP: pronoun, personal\n",
      "    hers herself him himself hisself it itself me myself one oneself ours\n",
      "    ourselves ownself self she thee theirs them themselves they thou thy us\n",
      "your :\n",
      "PRP$: pronoun, possessive\n",
      "    her his mine my our ours their thy your\n",
      "ears :\n",
      "NNS: noun, common, plural\n",
      "    undergraduates scotches bric-a-brac products bodyguards facets coasts\n",
      "    divestitures storehouses designs clubs fragrances averages\n",
      "    subjectivists apprehensions muses factory-jobs ...\n",
      "; :\n",
      ":: colon or ellipsis\n",
      "    : ; ...\n",
      "I :\n",
      "PRP: pronoun, personal\n",
      "    hers herself him himself hisself it itself me myself one oneself ours\n",
      "    ourselves ownself self she thee theirs them themselves they thou thy us\n",
      "come :\n",
      "VBP: verb, present tense, not 3rd person singular\n",
      "    predominate wrap resort sue twist spill cure lengthen brush terminate\n",
      "    appear tend stray glisten obtain comprise detest tease attract\n",
      "    emphasize mold postpone sever return wag ...\n",
      "to :\n",
      "TO: \"to\" as preposition or infinitive marker\n",
      "    to\n",
      "bury :\n",
      "VB: verb, base form\n",
      "    ask assemble assess assign assume atone attention avoid bake balkanize\n",
      "    bank begin behold believe bend benefit bevel beware bless boil bomb\n",
      "    boost brace break bring broil brush build ...\n",
      "Caesar :\n",
      "NNP: noun, proper, singular\n",
      "    Motown Venneboerger Czestochwa Ranzer Conchita Trumplane Christos\n",
      "    Oceanside Escobar Kreisler Sawyer Cougar Yvette Ervin ODI Darryl CTCA\n",
      "    Shannon A.K.C. Meltex Liverpool ...\n",
      ", :\n",
      ",: comma\n",
      "    ,\n",
      "not :\n",
      "RB: adverb\n",
      "    occasionally unabatingly maddeningly adventurously professedly\n",
      "    stirringly prominently technologically magisterially predominately\n",
      "    swiftly fiscally pitilessly ...\n",
      "to :\n",
      "TO: \"to\" as preposition or infinitive marker\n",
      "    to\n",
      "praise :\n",
      "VB: verb, base form\n",
      "    ask assemble assess assign assume atone attention avoid bake balkanize\n",
      "    bank begin behold believe bend benefit bevel beware bless boil bomb\n",
      "    boost brace break bring broil brush build ...\n",
      "him :\n",
      "PRP: pronoun, personal\n",
      "    hers herself him himself hisself it itself me myself one oneself ours\n",
      "    ourselves ownself self she thee theirs them themselves they thou thy us\n",
      ". :\n",
      ".: sentence terminator\n",
      "    . ! ?\n",
      "The :\n",
      "DT: determiner\n",
      "    all an another any both del each either every half la many much nary\n",
      "    neither no some such that the them these this those\n",
      "evil :\n",
      "JJ: adjective or numeral, ordinal\n",
      "    third ill-mannered pre-war regrettable oiled calamitous first separable\n",
      "    ectoplasmic battery-powered participatory fourth still-to-be-named\n",
      "    multilingual multi-disciplinary ...\n",
      "that :\n",
      "IN: preposition or conjunction, subordinating\n",
      "    astride among uppon whether out inside pro despite on by throughout\n",
      "    below within for towards near behind atop around if like until below\n",
      "    next into if beside ...\n",
      "men :\n",
      "NNS: noun, common, plural\n",
      "    undergraduates scotches bric-a-brac products bodyguards facets coasts\n",
      "    divestitures storehouses designs clubs fragrances averages\n",
      "    subjectivists apprehensions muses factory-jobs ...\n",
      "do :\n",
      "VBP: verb, present tense, not 3rd person singular\n",
      "    predominate wrap resort sue twist spill cure lengthen brush terminate\n",
      "    appear tend stray glisten obtain comprise detest tease attract\n",
      "    emphasize mold postpone sever return wag ...\n",
      "lives :\n",
      "NNS: noun, common, plural\n",
      "    undergraduates scotches bric-a-brac products bodyguards facets coasts\n",
      "    divestitures storehouses designs clubs fragrances averages\n",
      "    subjectivists apprehensions muses factory-jobs ...\n",
      "after :\n",
      "IN: preposition or conjunction, subordinating\n",
      "    astride among uppon whether out inside pro despite on by throughout\n",
      "    below within for towards near behind atop around if like until below\n",
      "    next into if beside ...\n",
      "them :\n",
      "PRP: pronoun, personal\n",
      "    hers herself him himself hisself it itself me myself one oneself ours\n",
      "    ourselves ownself self she thee theirs them themselves they thou thy us\n",
      "; :\n",
      ":: colon or ellipsis\n",
      "    : ; ...\n",
      "The :\n",
      "DT: determiner\n",
      "    all an another any both del each either every half la many much nary\n",
      "    neither no some such that the them these this those\n",
      "good :\n",
      "JJ: adjective or numeral, ordinal\n",
      "    third ill-mannered pre-war regrettable oiled calamitous first separable\n",
      "    ectoplasmic battery-powered participatory fourth still-to-be-named\n",
      "    multilingual multi-disciplinary ...\n",
      "is :\n",
      "VBZ: verb, present tense, 3rd person singular\n",
      "    bases reconstructs marks mixes displeases seals carps weaves snatches\n",
      "    slumps stretches authorizes smolders pictures emerges stockpiles\n",
      "    seduces fizzes uses bolsters slaps speaks pleads ...\n",
      "oft :\n",
      "JJ: adjective or numeral, ordinal\n",
      "    third ill-mannered pre-war regrettable oiled calamitous first separable\n",
      "    ectoplasmic battery-powered participatory fourth still-to-be-named\n",
      "    multilingual multi-disciplinary ...\n",
      "interred :\n",
      "VBN: verb, past participle\n",
      "    multihulled dilapidated aerosolized chaired languished panelized used\n",
      "    experimented flourished imitated reunifed factored condensed sheared\n",
      "    unsettled primed dubbed desired ...\n",
      "with :\n",
      "IN: preposition or conjunction, subordinating\n",
      "    astride among uppon whether out inside pro despite on by throughout\n",
      "    below within for towards near behind atop around if like until below\n",
      "    next into if beside ...\n",
      "their :\n",
      "PRP$: pronoun, possessive\n",
      "    her his mine my our ours their thy your\n",
      "bones :\n",
      "NNS: noun, common, plural\n",
      "    undergraduates scotches bric-a-brac products bodyguards facets coasts\n",
      "    divestitures storehouses designs clubs fragrances averages\n",
      "    subjectivists apprehensions muses factory-jobs ...\n",
      "; :\n",
      ":: colon or ellipsis\n",
      "    : ; ...\n",
      "So :\n",
      "NNP: noun, proper, singular\n",
      "    Motown Venneboerger Czestochwa Ranzer Conchita Trumplane Christos\n",
      "    Oceanside Escobar Kreisler Sawyer Cougar Yvette Ervin ODI Darryl CTCA\n",
      "    Shannon A.K.C. Meltex Liverpool ...\n",
      "let :\n",
      "VB: verb, base form\n",
      "    ask assemble assess assign assume atone attention avoid bake balkanize\n",
      "    bank begin behold believe bend benefit bevel beware bless boil bomb\n",
      "    boost brace break bring broil brush build ...\n",
      "it :\n",
      "PRP: pronoun, personal\n",
      "    hers herself him himself hisself it itself me myself one oneself ours\n",
      "    ourselves ownself self she thee theirs them themselves they thou thy us\n",
      "be :\n",
      "VB: verb, base form\n",
      "    ask assemble assess assign assume atone attention avoid bake balkanize\n",
      "    bank begin behold believe bend benefit bevel beware bless boil bomb\n",
      "    boost brace break bring broil brush build ...\n",
      "with :\n",
      "IN: preposition or conjunction, subordinating\n",
      "    astride among uppon whether out inside pro despite on by throughout\n",
      "    below within for towards near behind atop around if like until below\n",
      "    next into if beside ...\n",
      "Caesar :\n",
      "NNP: noun, proper, singular\n",
      "    Motown Venneboerger Czestochwa Ranzer Conchita Trumplane Christos\n",
      "    Oceanside Escobar Kreisler Sawyer Cougar Yvette Ervin ODI Darryl CTCA\n",
      "    Shannon A.K.C. Meltex Liverpool ...\n",
      ". :\n",
      ".: sentence terminator\n",
      "    . ! ?\n"
     ]
    }
   ],
   "source": [
    "for pos_tag_word in pos_tagged_text:\n",
    "    print(pos_tag_word[0], \":\")\n",
    "    nltk.help.upenn_tagset(pos_tag_word[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e095bf1d",
   "metadata": {},
   "source": [
    "## Exercise\n",
    "\n",
    "Repeat this exercise using other text, especially text where there is structurl ambiguity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "751f5056",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "jupytext": {
   "encoding": "# -*- coding: utf-8 -*-",
   "formats": "ipynb,py:percent"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
