<!DOCTYPE html>
<html lang="en">
  <head>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1">

    <title>MSc Data Mining</title>

    <!-- Bootstrap core CSS -->
    <link href="../../../style/bootstrap/css/bootstrap.min.css" rel="stylesheet">
<link href="//maxcdn.bootstrapcdn.com/font-awesome/4.2.0/css/font-awesome.min.css" rel="stylesheet">

    <!-- Custom styles for this template -->
    <link href="../../../style/codehilite/css/default.css" rel="stylesheet">
    <link href="../../../style/misc/css/module.css" rel="stylesheet">
    <link href="../../../style/misc/css/practical.css" rel="stylesheet">

    <!-- HTML5 shim and Respond.js IE8 support of HTML5 elements and media queries -->
    <!--[if lt IE 9]>
      <script src="https://oss.maxcdn.com/html5shiv/3.7.2/html5shiv.min.js"></script>
      <script src="https://oss.maxcdn.com/respond/1.4.2/respond.min.js"></script>
    <![endif]-->

	<script type="text/javascript"
	  src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML">
	</script>

  </head>

<body>

	<!-- Fixed navbar -->
	<div class="navbar navbar-default navbar-fixed-top" role="navigation">
		<div class="container">
			
			
	    	<div class="collapse navbar-collapse">

				<ul class="nav navbar-nav navbar-left">
					<!-- Moodle -->
					<li>
						<div class="navbar-header">
							<a class="navbar-brand" href="https://moodle.wit.ie/course/view.php?id=192151" target="_blank"><img height="18pt" src="../../../style/misc/img/moodle_logo_on_blue.gif" /></a>
						</div>						
					</li>
					<li>
						<div class="navbar-header">
							<a class="navbar-brand" href="https://moodle.wit.ie/course/view.php?id=192151" target="_blank"><img height="18pt" src="../../../style/misc/img/slack_logo.png" /></a>
						</div>						
					</li>
				</ul>

	      		<ul class="nav navbar-nav navbar-right">

					<!-- module home -->
					<li>
						<div class="navbar-header">
							<a class="navbar-brand" href="../../../index.html"><span class="glyphicon glyphicon-home"></span></a>
						</div>						
					</li>
					
					<!-- topics -->
	        		<li>
						<div class="navbar-collapse collapse" id="b">
							<ul class="nav navbar-nav">
								<li class="dropdown">
									<a href="#" class="dropdown-toggle" data-toggle="dropdown">
										<span class="glyphicon glyphicon-list-alt"></span>
									</a>
									<ul class="dropdown-menu" role="menu">
										<li class="dropdown-header">Topics</li>
										
										<li >
											<a href="../../../topics/01-Module_Overview/index.html">Module Overview</a>
										</li>
										
										<li >
											<a href="../../../topics/02-Exploratory_Data_Analysis/index.html">Exploratory Data Analysis</a>
										</li>
										
										<li >
											<a href="../../../topics/03-Data_Modelling_-_Introduction/index.html">Data Modelling - Introduction</a>
										</li>
										
										<li >
											<a href="../../../topics/04-Regression/index.html">Regression</a>
										</li>
										
										<li >
											<a href="../../../topics/05-Classification/index.html">Classification</a>
										</li>
										
										<li >
											<a href="../../../topics/06-Data_Modelling_-_Advanced/index.html">Data Modelling - Advanced</a>
										</li>
										
										<li >
											<a href="../../../topics/07-Advanced_Classification/index.html">Advanced Classification</a>
										</li>
										
										<li >
											<a href="../../../topics/08-Clustering/index.html">Clustering</a>
										</li>
										
										<li >
											<a href="../../../topics/09-Association_Analysis/index.html">Association Analysis</a>
										</li>
										
										<li >
											<a href="../../../topics/10-Anomaly_Detection_and_Recommendation_Systems/index.html">Anomaly Detection and Recommendation Systems</a>
										</li>
										
										<li class="active">
											<a href="../../../topics/11-Deep_Learning/index.html">Deep Learning</a>
										</li>
										
										<li >
											<a href="../../../topics/12-Text_Mining/index.html">Text Mining</a>
										</li>
										
										<li >
											<a href="../../../topics/21-Assignments/index.html">Assignments</a>
										</li>
										
									</ul>
								</li>
							</ul>
						</div>			
					</li>

					<!-- resources -->
	        		<li>
						<div class="navbar-collapse collapse" id="b">
							<ul class="nav navbar-nav">
								<li class="dropdown">
									<a href="#" class="dropdown-toggle" data-toggle="dropdown">
										<span class="glyphicon glyphicon-th-list"></span>
									</a>
									<ul class="dropdown-menu" role="menu">
										<li class="dropdown-header">Resources</li>
										
										<li >
											<a href="../../../topics/11-Deep_Learning/index.html#01-Neural_Networks">Neural Networks</a>
										</li>
										
										<li class="active">
											<a href="../../../topics/11-Deep_Learning/index.html#21-Lab_11_-_MNIST_using_Keras">Lab 11 - MNIST using Keras</a>
										</li>
										
									</ul>
								</li>
							</ul>
						</div>			
					</li>
								
					<!-- pages-->
	        		<li>
						<div class="navbar-collapse collapse" id="c">
							<ul class="nav navbar-nav">
								<li class="dropdown">
									<a href="#" class="dropdown-toggle" data-toggle="dropdown">
										<span>Outline</span
									</a>
									<ul class="dropdown-menu" role="menu">
										
										<li class="active">
											<a href="00-Outline.html">Outline</a>
										</li>
										
									</ul>
								</li>
							</ul>
						</div>			
					</li> 
					
	        	</ul>
			</div>
		</div>
	</div>

	<!-- contents -->
	<div class="container">
		
		<ul class="pager">
			
			<li class="previous disabled"><a>&larr; Previous</a></li>
			
			
			
			<li class="next disabled"><a>Next &rarr;</a></li>
			
		</ul>
		
		<h1>MNIST and Keras</h1>
<p>Because you all have a number of assignments coming due soon this is a short practical. WE will use keras/tensorflow in a multi-class classification (10-levels) of the MNIST hand written digits dataset.</p>
<ul>
<li>Basic keras/tensorflow usage.</li>
<li>Effect of number of nodes in a single hidden layer network (theory vs practice).</li>
<li>Effect of adding more hidden layers.</li>
<li>Dense vs CNN in terms of number of parameters and model performance.</li>
</ul>
<h2>Imports and Setup</h2>
<p>First import our three standard python modules for data mining</p>
<table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span class="normal">1</span>
<span class="normal">2</span>
<span class="normal">3</span></pre></div></td><td class="code"><div class="highlight"><pre><span></span><code><span class="n">impoort</span> <span class="n">numpy</span> <span class="k">as</span> <span class="n">np</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>
<span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>
</code></pre></div>
</td></tr></table>
<p>Now we import <code>keras</code> and <code>keras.layers</code>.  This is different from the imports used in the lecture but it probably more convenient. (To install both, see lecture notes.)</p>
<table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span class="normal">1</span>
<span class="normal">2</span></pre></div></td><td class="code"><div class="highlight"><pre><span></span><code><span class="kn">from</span> <span class="nn">tensorflow</span> <span class="kn">import</span> <span class="n">keras</span>
<span class="kn">from</span> <span class="nn">tensorflow.keras</span> <span class="kn">import</span> <span class="n">layers</span>
</code></pre></div>
</td></tr></table>
<h2>Dataset</h2>
<p>The MNIST dataset consists of 70,000 hand-written digits, each digit is stored in a 28x28 grayscale image. This dataset has been extensively studied and is complex enough to benefit from using neural networks, but small enough that training times are not an issue.</p>
<p>If you have followed along in the earlier weeks, then you have downloaded the dataset already. But to keep things consistent today we will use the version of the MNIST dataset from keras. </p>
<table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span class="normal">1</span>
<span class="normal">2</span></pre></div></td><td class="code"><div class="highlight"><pre><span></span><code><span class="p">(</span><span class="n">x_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">),</span> <span class="p">(</span><span class="n">x_test</span><span class="p">,</span> <span class="n">y_test</span><span class="p">)</span> <span class="o">=</span> <span class="n">keras</span><span class="o">.</span><span class="n">datasets</span><span class="o">.</span><span class="n">mnist</span><span class="o">.</span><span class="n">load_data</span><span class="p">()</span>
<span class="n">x_train</span><span class="o">.</span><span class="n">shape</span><span class="p">,</span> <span class="n">y_train</span><span class="o">.</span><span class="n">shape</span><span class="p">,</span> <span class="n">x_test</span><span class="o">.</span><span class="n">shape</span><span class="p">,</span> <span class="n">y_test</span><span class="o">.</span><span class="n">shape</span>
</code></pre></div>
</td></tr></table>
<p>This should produce output</p>
<table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span class="normal">1</span></pre></div></td><td class="code"><div class="highlight"><pre><span></span><code>((60000, 28, 28), (60000,), (10000, 28, 28), (10000,))
</code></pre></div>
</td></tr></table>
<p>So we have split the 70,000 observations into 60,000 for training and 10,000 for testing.  Each of the observations consists of a 28z28 pixel image. Each pixel is a single integer in range 0..255.</p>
<p>The following code show the first 24 observations and their labels. Note that the images are in grayscale (so each pixel is a single value), and the colouring is only mapping.</p>
<table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span class="normal"> 1</span>
<span class="normal"> 2</span>
<span class="normal"> 3</span>
<span class="normal"> 4</span>
<span class="normal"> 5</span>
<span class="normal"> 6</span>
<span class="normal"> 7</span>
<span class="normal"> 8</span>
<span class="normal"> 9</span>
<span class="normal">10</span>
<span class="normal">11</span></pre></div></td><td class="code"><div class="highlight"><pre><span></span><code><span class="n">k</span> <span class="o">=</span> <span class="mi">10</span>
<span class="n">fig</span><span class="p">,</span> <span class="n">axs</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="mi">4</span><span class="p">,</span><span class="mi">6</span><span class="p">,</span> <span class="n">sharex</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">sharey</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">16</span><span class="p">,</span><span class="mi">10</span><span class="p">))</span>

<span class="k">for</span> <span class="n">ax</span> <span class="ow">in</span> <span class="n">axs</span><span class="o">.</span><span class="n">flat</span><span class="p">:</span>
    <span class="n">k</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">randint</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span><span class="n">x_train</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">imshow</span><span class="p">(</span><span class="n">x_train</span><span class="p">[</span><span class="n">k</span><span class="p">])</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="n">y_train</span><span class="p">[</span><span class="n">k</span><span class="p">]);</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">suptitle</span><span class="p">(</span><span class="s2">&quot;Sample digits in training set&quot;</span><span class="p">)</span>

<span class="n">plt</span><span class="o">.</span><span class="n">savefig</span><span class="p">(</span><span class="s2">&quot;output/Sample_digits_in_training.png&quot;</span><span class="p">,</span> <span class="n">bbox_inches</span><span class="o">=</span><span class="s2">&quot;tight&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</code></pre></div>
</td></tr></table>
<figure>
<img src="files/Sample_digits_in_training.png" width="100%">
<figcaption>First 24 inputs and their labels. </figcaption>
</figure>

<h2>Preprocessing</h2>
<p>First we scale the inputs from range 0..255 to 0..1.</p>
<table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span class="normal">1</span>
<span class="normal">2</span>
<span class="normal">3</span></pre></div></td><td class="code"><div class="highlight"><pre><span></span><code><span class="c1"># Scale images to the [0, 1] range</span>
<span class="n">x_train</span> <span class="o">=</span> <span class="n">x_train</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="s2">&quot;float32&quot;</span><span class="p">)</span> <span class="o">/</span> <span class="mi">255</span>
<span class="n">x_test</span> <span class="o">=</span> <span class="n">x_test</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="s2">&quot;float32&quot;</span><span class="p">)</span> <span class="o">/</span> <span class="mi">255</span>
</code></pre></div>
</td></tr></table>
<p>Then add an extra dimension to the input data, so that the last dimension has size one. This is expected by the neural network.</p>
<table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span class="normal">1</span>
<span class="normal">2</span>
<span class="normal">3</span>
<span class="normal">4</span>
<span class="normal">5</span></pre></div></td><td class="code"><div class="highlight"><pre><span></span><code><span class="c1"># Make sure images have shape (28, 28, 1)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;original x_train shape:&quot;</span><span class="p">,</span> <span class="n">x_train</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
<span class="n">x_train</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">expand_dims</span><span class="p">(</span><span class="n">x_train</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">)</span>
<span class="n">x_test</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">expand_dims</span><span class="p">(</span><span class="n">x_test</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;x_train shape:&quot;</span><span class="p">,</span> <span class="n">x_train</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
</code></pre></div>
</td></tr></table>
<p>This should produce output</p>
<table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span class="normal">1</span>
<span class="normal">2</span></pre></div></td><td class="code"><div class="highlight"><pre><span></span><code>original x_train shape: (60000, 28, 28)
x_train shape: (60000, 28, 28, 1)
</code></pre></div>
</td></tr></table>
<p>Then we convert the single valued output (with 10 values) to a vector of 10-binary values (i.e., one-hot encoding)</p>
<table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span class="normal">1</span>
<span class="normal">2</span>
<span class="normal">3</span></pre></div></td><td class="code"><div class="highlight"><pre><span></span><code><span class="c1"># convert class vectors to binary class matrices</span>
<span class="n">y_train</span> <span class="o">=</span> <span class="n">keras</span><span class="o">.</span><span class="n">utils</span><span class="o">.</span><span class="n">to_categorical</span><span class="p">(</span><span class="n">y_train</span><span class="p">,</span> <span class="mi">10</span><span class="p">)</span>
<span class="n">y_test</span> <span class="o">=</span> <span class="n">keras</span><span class="o">.</span><span class="n">utils</span><span class="o">.</span><span class="n">to_categorical</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="mi">10</span><span class="p">)</span>
</code></pre></div>
</td></tr></table>
<h2>Dense, Single Hidden Layer Model</h2>
<p>Our first neural network will be a single layer, fully connected (as in slide 24 of lecture notes). To create this we write</p>
<table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span class="normal"> 1</span>
<span class="normal"> 2</span>
<span class="normal"> 3</span>
<span class="normal"> 4</span>
<span class="normal"> 5</span>
<span class="normal"> 6</span>
<span class="normal"> 7</span>
<span class="normal"> 8</span>
<span class="normal"> 9</span>
<span class="normal">10</span>
<span class="normal">11</span>
<span class="normal">12</span></pre></div></td><td class="code"><div class="highlight"><pre><span></span><code><span class="n">model</span> <span class="o">=</span> <span class="n">keras</span><span class="o">.</span><span class="n">Sequential</span><span class="p">([</span>

    <span class="c1"># input layer </span>
    <span class="n">keras</span><span class="o">.</span><span class="n">Input</span><span class="p">(</span><span class="n">shape</span><span class="o">=</span><span class="p">(</span><span class="mi">28</span><span class="p">,</span><span class="mi">28</span><span class="p">,</span><span class="mi">1</span><span class="p">)),</span>
    <span class="n">layers</span><span class="o">.</span><span class="n">Flatten</span><span class="p">(</span><span class="n">input_shape</span><span class="o">=</span><span class="p">(</span><span class="mi">28</span><span class="p">,</span> <span class="mi">28</span><span class="p">,</span><span class="mi">1</span><span class="p">)),</span>

    <span class="c1"># hidden layer</span>
    <span class="n">layers</span><span class="o">.</span><span class="n">Dense</span><span class="p">(</span><span class="mi">15</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s2">&quot;relu&quot;</span><span class="p">),</span>

    <span class="c1"># output layer</span>
    <span class="n">layers</span><span class="o">.</span><span class="n">Dense</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s2">&quot;softmax&quot;</span><span class="p">),</span>
<span class="p">])</span>
</code></pre></div>
</td></tr></table>
<p>There is a number of points to note:</p>
<ul>
<li>The input <code>x_train</code> and <code>x_test</code> are a list of 2-dimensional 28x28 images. So the first step is to flatten the images to be 1-dimensional. This is the role of 
 <code>layers.Flatten</code>.  We could have converted to data to 1D before passing into the neural network using the numpy method <code>reshape</code>.</li>
<li>If we want to see how many parameters are in the network we can use <code>model.count_params()</code>.  This network has 12,175 parameters.</li>
<li>Function <code>model.summary()</code> generates a summary of the network and the number of trainable parameters pere layer:</li>
</ul>
<table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span class="normal"> 1</span>
<span class="normal"> 2</span>
<span class="normal"> 3</span>
<span class="normal"> 4</span>
<span class="normal"> 5</span>
<span class="normal"> 6</span>
<span class="normal"> 7</span>
<span class="normal"> 8</span>
<span class="normal"> 9</span>
<span class="normal">10</span>
<span class="normal">11</span>
<span class="normal">12</span>
<span class="normal">13</span>
<span class="normal">14</span>
<span class="normal">15</span>
<span class="normal">16</span>
<span class="normal">17</span></pre></div></td><td class="code"><div class="highlight"><pre><span></span><code>Model: &quot;sequential_1&quot;
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_4 (Flatten)         (None, 784)               0         

 dense_10 (Dense)            (None, 15)                11775     

 dense_11 (Dense)            (None, 15)                240       

 dense_12 (Dense)            (None, 10)                160       

=================================================================
Total params: 12,175
Trainable params: 12,175
Non-trainable params: 0
_________________________________________________________________
</code></pre></div>
</td></tr></table>
<p>To train we use </p>
<table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span class="normal">1</span>
<span class="normal">2</span>
<span class="normal">3</span>
<span class="normal">4</span>
<span class="normal">5</span>
<span class="normal">6</span>
<span class="normal">7</span></pre></div></td><td class="code"><div class="highlight"><pre><span></span><code><span class="n">batch_size</span> <span class="o">=</span> <span class="mi">128</span>
<span class="n">epochs</span> <span class="o">=</span> <span class="mi">15</span>

<span class="n">model</span><span class="o">.</span><span class="n">compile</span><span class="p">(</span><span class="n">loss</span><span class="o">=</span><span class="s2">&quot;categorical_crossentropy&quot;</span><span class="p">,</span> <span class="n">optimizer</span><span class="o">=</span><span class="s2">&quot;adam&quot;</span><span class="p">,</span> 
    <span class="n">metrics</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;accuracy&quot;</span><span class="p">])</span>

<span class="n">model</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">x_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="n">batch_size</span><span class="p">,</span> <span class="n">epochs</span><span class="o">=</span><span class="n">epochs</span><span class="p">,</span> <span class="n">validation_split</span><span class="o">=</span><span class="mf">0.1</span><span class="p">)</span>
</code></pre></div>
</td></tr></table>
<p>and to score we use</p>
<table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span class="normal">1</span>
<span class="normal">2</span>
<span class="normal">3</span></pre></div></td><td class="code"><div class="highlight"><pre><span></span><code><span class="n">score</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">evaluate</span><span class="p">(</span><span class="n">x_test</span><span class="p">,</span> <span class="n">y_test</span><span class="p">,</span> <span class="n">verbose</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Test loss:&quot;</span><span class="p">,</span> <span class="n">score</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Test accuracy:&quot;</span><span class="p">,</span> <span class="n">score</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span>
</code></pre></div>
</td></tr></table>
<p>This generates output </p>
<table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span class="normal">1</span>
<span class="normal">2</span></pre></div></td><td class="code"><div class="highlight"><pre><span></span><code>Test loss: 0.1866159439086914
Test accuracy: 0.9476000070571899
</code></pre></div>
</td></tr></table>
<h3>Effect of (Single) Hidden Layer Size</h3>
<p>During the lecture (slide 15) we mentioned the result that said any bounded continuous function can by approximated with arbitrarily small error, by network with one hidden layer [Cybenko 1989; Hornik et al. 1989].  Lets see what happens to the accuracy when we increase the size of the hidden layer for this problem.</p>
<p>Steps:</p>
<ul>
<li>Create a range of sizes for the number of nodes in the hidden layer and empty lists to store the resulting number of parameters and the accuracy.</li>
</ul>
<table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span class="normal">1</span>
<span class="normal">2</span>
<span class="normal">3</span></pre></div></td><td class="code"><div class="highlight"><pre><span></span><code><span class="n">sizes</span> <span class="o">=</span> <span class="p">[</span><span class="mi">2</span><span class="o">**</span><span class="n">k</span> <span class="k">for</span> <span class="n">k</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">4</span><span class="p">,</span> <span class="mi">10</span><span class="p">)]</span>
<span class="n">params</span> <span class="o">=</span> <span class="p">[]</span>
<span class="n">accuracy</span> <span class="o">=</span> <span class="p">[]</span>
</code></pre></div>
</td></tr></table>
<p>Then using a loop structure like </p>
<table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span class="normal"> 1</span>
<span class="normal"> 2</span>
<span class="normal"> 3</span>
<span class="normal"> 4</span>
<span class="normal"> 5</span>
<span class="normal"> 6</span>
<span class="normal"> 7</span>
<span class="normal"> 8</span>
<span class="normal"> 9</span>
<span class="normal">10</span>
<span class="normal">11</span>
<span class="normal">12</span>
<span class="normal">13</span>
<span class="normal">14</span></pre></div></td><td class="code"><div class="highlight"><pre><span></span><code><span class="k">for</span> <span class="n">size</span> <span class="ow">in</span> <span class="n">sizes</span><span class="p">:</span>

    <span class="nb">print</span><span class="p">(</span><span class="n">size</span><span class="p">)</span>

    <span class="c1">## define model</span>

    <span class="c1">## train model - use option verbose=0 to kill off output!</span>

    <span class="c1">## append number of param in current model to params</span>
    <span class="n">params</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">count_params</span><span class="p">())</span>

    <span class="c1">## append accuracy in current model to accuracy</span>
    <span class="n">score</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">evaluate</span><span class="p">(</span><span class="n">x_test</span><span class="p">,</span> <span class="n">y_test</span><span class="p">,</span> <span class="n">verbose</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
    <span class="n">accuracy</span><span class="o">.</span><span class="n">append</span><span class="p">(</span> <span class="n">score</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="p">)</span>
</code></pre></div>
</td></tr></table>
<p>You should get </p>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right; padding: 0px 45px;">
      <th>size</th>
      <th>16</th>
      <th>32</th>
      <th>64</th>
      <th>128</th>
      <th>256</th>
      <th>512</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>param</th>
      <td>12,730</td>
      <td>25,450</td>
      <td>50,890</td>
      <td>101,770</td>
      <td>203,530</td>
      <td>407,050</td>
    </tr>
    <tr>
      <th>accuracy</th>
      <td>0.9474</td>
      <td>0.9659</td>
      <td>0.9744</td>
      <td>0.9787</td>
      <td>0.9816</td>
      <td>0.9808</td>
    </tr>
  </tbody>
</table>

<p>and graphically</p>
<figure>
<img src="files/single_hidden_layer_nodes_vs_accuracy.png" width="50%">
<figcaption>Impact of hidden layer size on model accuracy. </figcaption>
</figure>

<p>As you can see the accuracy initially increased as more nodes were added to the hidden layer but the accuracy maxed out at 98.2% and seem be decreasing (I have not checked) when number of nodes approaches 512. It is possible to do better than
98.2%, so what has gone wrong?</p>
<ul>
<li>
<p>The Cybenko and Hornik et al. results say arbitrary high accuracy is possible, but does not say how easy/difficult it is to achieve.</p>
</li>
<li>
<p>The issue here could be the effort to train as the number of parameters increase. With 512 nodes in the hidden layer, there are 407,050 trainable parameters.  We could up the number of iterations for training but the problem here is that half a million parameters for such a simple classification problem is silly. </p>
</li>
</ul>
<p>### Effect of Multiple Hidden Layers</p>
<p>OK, so lets see what happens when we add multiple hidden layers. To keep things simple we will just add multiple hidden layers of size 16 nodes.</p>
<p>The setup and loop in nearly the same as before except now you need to used the <code>model.add</code> method to programmatically add the hidden layer as apposed </p>
<table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span class="normal">1</span>
<span class="normal">2</span>
<span class="normal">3</span></pre></div></td><td class="code"><div class="highlight"><pre><span></span><code><span class="n">num_layers</span> <span class="o">=</span> <span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="mi">6</span><span class="p">)</span>
<span class="n">params</span> <span class="o">=</span> <span class="p">[]</span>
<span class="n">accuracy</span> <span class="o">=</span> <span class="p">[]</span>
</code></pre></div>
</td></tr></table>
<p>Then using a loop structure like </p>
<table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span class="normal"> 1</span>
<span class="normal"> 2</span>
<span class="normal"> 3</span>
<span class="normal"> 4</span>
<span class="normal"> 5</span>
<span class="normal"> 6</span>
<span class="normal"> 7</span>
<span class="normal"> 8</span>
<span class="normal"> 9</span>
<span class="normal">10</span>
<span class="normal">11</span>
<span class="normal">12</span>
<span class="normal">13</span>
<span class="normal">14</span>
<span class="normal">15</span>
<span class="normal">16</span>
<span class="normal">17</span>
<span class="normal">18</span>
<span class="normal">19</span></pre></div></td><td class="code"><div class="highlight"><pre><span></span><code><span class="k">for</span> <span class="n">num</span> <span class="ow">in</span> <span class="n">num_layers</span><span class="p">:</span>

    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Number of Hidden Layers&quot;</span><span class="p">,</span> <span class="n">num</span><span class="p">)</span>

    <span class="c1">## define model</span>
    <span class="n">model</span> <span class="o">=</span> <span class="n">keras</span><span class="o">.</span><span class="n">Sequential</span><span class="p">()</span>
    <span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">keras</span><span class="o">.</span><span class="n">Input</span><span class="p">(</span><span class="n">shape</span><span class="o">=</span><span class="p">(</span><span class="mi">28</span><span class="p">,</span><span class="mi">28</span><span class="p">)))</span>
    <span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">layers</span><span class="o">.</span><span class="n">Flatten</span><span class="p">(</span><span class="n">input_shape</span><span class="o">=</span><span class="p">(</span><span class="mi">28</span><span class="p">,</span> <span class="mi">28</span><span class="p">)))</span>
    <span class="c1"># ... and so on using a loop to add the num hidden layers</span>


    <span class="c1">## train model - use option verbose=0 to kill off output!</span>

    <span class="c1">## append number of param in current model to params</span>
    <span class="n">params</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">count_params</span><span class="p">())</span>

    <span class="c1">## append accuracy in current model to accuracy</span>
    <span class="n">score</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">evaluate</span><span class="p">(</span><span class="n">x_test</span><span class="p">,</span> <span class="n">y_test</span><span class="p">,</span> <span class="n">verbose</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
    <span class="n">accuracy</span><span class="o">.</span><span class="n">append</span><span class="p">(</span> <span class="n">score</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="p">)</span>
</code></pre></div>
</td></tr></table>
<p>You should get </p>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th>num_layers</th>
      <th>1</th>
      <th>2</th>
      <th>3</th>
      <th>4</th>
      <th>5</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>param</th>
      <td>12,730</td>
      <td>13,002</td>
      <td>13,274</td>
      <td>13,546</td>
      <td>13,818</td>
    </tr>
    <tr>
      <th>accuracy</th>
      <td>0.9487</td>
      <td>0.9545</td>
      <td>0.9545</td>
      <td>0.9559</td>
      <td>0.9496</td>
    </tr>
  </tbody>
</table>

<p>and graphically</p>
<figure>
<img src="files/multiple_hidden_layer_param_vs_accuracy.png" width="50%">
<figcaption>Impact of number of hidden layer size on model accuracy. </figcaption>
</figure>

<p>This is a bit disappointing - we are not breaking the 99% accuracy barrier. Again training difficulty as the number of parameters increase is the issue.</p>
<p>We could work harder and spend more time training, or work smarter and use a better network structure &mdash; did anyone say convolution neural networks?</p>
<h2>CNN Approach</h2>
<p>Using </p>
<table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span class="normal"> 1</span>
<span class="normal"> 2</span>
<span class="normal"> 3</span>
<span class="normal"> 4</span>
<span class="normal"> 5</span>
<span class="normal"> 6</span>
<span class="normal"> 7</span>
<span class="normal"> 8</span>
<span class="normal"> 9</span>
<span class="normal">10</span>
<span class="normal">11</span></pre></div></td><td class="code"><div class="highlight"><pre><span></span><code><span class="n">model</span> <span class="o">=</span> <span class="n">keras</span><span class="o">.</span><span class="n">Sequential</span><span class="p">([</span>
    <span class="n">keras</span><span class="o">.</span><span class="n">Input</span><span class="p">(</span><span class="n">shape</span><span class="o">=</span><span class="n">input_shape</span><span class="p">),</span>

    <span class="n">layers</span><span class="o">.</span><span class="n">Conv2D</span><span class="p">(</span><span class="mi">32</span><span class="p">,</span> <span class="n">kernel_size</span><span class="o">=</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">),</span> <span class="n">activation</span><span class="o">=</span><span class="s2">&quot;relu&quot;</span><span class="p">),</span>
    <span class="n">layers</span><span class="o">.</span><span class="n">MaxPooling2D</span><span class="p">(</span><span class="n">pool_size</span><span class="o">=</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">)),</span>
    <span class="n">layers</span><span class="o">.</span><span class="n">Conv2D</span><span class="p">(</span><span class="mi">64</span><span class="p">,</span> <span class="n">kernel_size</span><span class="o">=</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">),</span> <span class="n">activation</span><span class="o">=</span><span class="s2">&quot;relu&quot;</span><span class="p">),</span>
    <span class="n">layers</span><span class="o">.</span><span class="n">MaxPooling2D</span><span class="p">(</span><span class="n">pool_size</span><span class="o">=</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">)),</span>
    <span class="n">layers</span><span class="o">.</span><span class="n">Flatten</span><span class="p">(),</span>
    <span class="n">layers</span><span class="o">.</span><span class="n">Dropout</span><span class="p">(</span><span class="mf">0.5</span><span class="p">),</span>
    <span class="n">layers</span><span class="o">.</span><span class="n">Dense</span><span class="p">(</span><span class="n">num_classes</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s2">&quot;softmax&quot;</span><span class="p">),</span>
<span class="p">])</span>
</code></pre></div>
</td></tr></table>
<p>Which, has <code>model.summary()</code> of</p>
<table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span class="normal"> 1</span>
<span class="normal"> 2</span>
<span class="normal"> 3</span>
<span class="normal"> 4</span>
<span class="normal"> 5</span>
<span class="normal"> 6</span>
<span class="normal"> 7</span>
<span class="normal"> 8</span>
<span class="normal"> 9</span>
<span class="normal">10</span>
<span class="normal">11</span>
<span class="normal">12</span>
<span class="normal">13</span>
<span class="normal">14</span>
<span class="normal">15</span>
<span class="normal">16</span>
<span class="normal">17</span>
<span class="normal">18</span>
<span class="normal">19</span>
<span class="normal">20</span>
<span class="normal">21</span>
<span class="normal">22</span>
<span class="normal">23</span>
<span class="normal">24</span>
<span class="normal">25</span></pre></div></td><td class="code"><div class="highlight"><pre><span></span><code>Model: &quot;sequential_1&quot;
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 conv2d_2 (Conv2D)           (None, 26, 26, 32)        320       

 max_pooling2d_2 (MaxPooling  (None, 13, 13, 32)       0         
 2D)                                                             

 conv2d_3 (Conv2D)           (None, 11, 11, 64)        18496     

 max_pooling2d_3 (MaxPooling  (None, 5, 5, 64)         0         
 2D)                                                             

 flatten_1 (Flatten)         (None, 1600)              0         

 dropout_1 (Dropout)         (None, 1600)              0         

 dense_1 (Dense)             (None, 10)                16010     

=================================================================
Total params: 34,826
Trainable params: 34,826
Non-trainable params: 0
_________________________________________________________________
</code></pre></div>
</td></tr></table>
<p>Apply this model and scoring it using </p>
<table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span class="normal">1</span>
<span class="normal">2</span>
<span class="normal">3</span></pre></div></td><td class="code"><div class="highlight"><pre><span></span><code><span class="n">score</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">evaluate</span><span class="p">(</span><span class="n">x_test</span><span class="p">,</span> <span class="n">y_test</span><span class="p">,</span> <span class="n">verbose</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Test loss:&quot;</span><span class="p">,</span> <span class="n">score</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Test accuracy:&quot;</span><span class="p">,</span> <span class="n">score</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span>
</code></pre></div>
</td></tr></table>
<p>we get test accuracy of 99.1%. This is the best yet and we have only 34,826 trainable parameters.</p>
<p><strong>Todo</strong></p>
<ul>
<li>You could see if you can determine a similar sized network with better performance. For example tweeking the dropout rate or even replacing <code>Dropout</code> with <code>BatchNormalization</code> are worth trying. </li>
</ul>
		
		<ul class="pager">
			
			<li class="previous disabled"><a>&larr; Previous</a></li>
			
			
			
			<li class="next disabled"><a>Next &rarr;</a></li>
			
		</ul>

	</div>
	
    <!-- Bootstrap core JavaScript
    ================================================== -->
    <!-- Placed at the end of the document so the pages load faster -->
    <script src="https://ajax.googleapis.com/ajax/libs/jquery/1.11.1/jquery.min.js"></script>
    <script src="../../../style/bootstrap/js/bootstrap.min.js"></script>
	
  </body>
</html>